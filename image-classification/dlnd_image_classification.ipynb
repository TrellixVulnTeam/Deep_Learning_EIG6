{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21dfb196a58>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    im_max = 255\n",
    "    im_min = 0\n",
    "    return (x-im_min)/(im_max - im_min)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = np.array(x)\n",
    "    number_of_class = max(x)\n",
    "    enc_x = np.zeros((len(x),10))\n",
    "    print(enc_x[1,:])\n",
    "    for i in range(len(x)):\n",
    "        enc_x[i,x[i]] = 1.0\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    return enc_x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], 'x')\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], 'y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     s = x_tensor.get_shape()\n",
    "    \n",
    "#     shape = tuple([s[i].value for i in range(0, len(s))])\n",
    "#     x = [conv_ksize[0], conv_ksize[1], x_tensor[0][0][3], conv_num_outputs]\n",
    "    print(conv_ksize)\n",
    "    W_conv = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_tensor.get_shape()[3].value, conv_num_outputs], stddev=0.1))\n",
    "    b_conv = tf.Variable(tf.constant(0.1, shape=[conv_num_outputs]))\n",
    "    \n",
    "    conv = tf.nn.conv2d(x_tensor, W_conv, strides=[1,conv_strides[0],conv_strides[1],1], padding='SAME')\n",
    "    relu = tf.nn.relu(conv + b_conv)\n",
    "    output = tf.nn.max_pool(relu, ksize=[1,pool_ksize[0],pool_ksize[1],1],\n",
    "                        strides=[1,pool_strides[0],pool_strides[1],1], padding='SAME')\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    s = x_tensor.get_shape()\n",
    "    \n",
    "    shape = tuple([s[i].value for i in range(0, len(s))])\n",
    "    \n",
    "    return tf.reshape(x_tensor, [-1, shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    W_fc = tf.Variable(tf.truncated_normal([x_tensor.get_shape()[1].value, num_outputs], stddev=0.1))\n",
    "    b_fc = tf.Variable(tf.constant(0.1, shape=[num_outputs]))\n",
    "    return tf.nn.bias_add(tf.matmul(x_tensor, W_fc), b_fc)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return fully_conn(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3]\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "[3, 3]\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    x = normalize(x)\n",
    "    conv1 = conv2d_maxpool(x, 32, [3,3], [1,1], [2,2], [1, 1])\n",
    "    conv2 = conv2d_maxpool(conv1, 64, (3,3), (1,1), (1,1), (1, 1))\n",
    "    conv3 = conv2d_maxpool(conv2, 64, (3,3), (1,1), (2,2), (1, 1))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(conv1)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc = fully_conn(flat, 512)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = tf.nn.dropout(fc, keep_prob,name=\"keep_prob\")\n",
    "    final = output(out, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return final\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... current loss: <MagicMock name='mock()' id='2325725854016'>Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    import sys\n",
    "    train_feed_dict = {x: feature_batch, y: label_batch, keep_prob:keep_probability}\n",
    "    #l = session.run(cost, feed_dict=train_feed_dict)\n",
    "    l = session.run([cost,optimizer], feed_dict=train_feed_dict)\n",
    "    sys.stdout.write(\"\\r ... current loss: \" + str(l))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    import sys\n",
    "    valid_feed_dict = {x: valid_features, y: valid_labels, keep_prob: 1.0}\n",
    "    l,acc = session.run([cost,accuracy], feed_dict=valid_feed_dict)\n",
    "    sys.stdout.write(\"\\r ...Validation loss: \" + str(l)[:5] \\\n",
    "                 + \" ... Validation accuracy: \" + str(acc)[:5] + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      " ... this loss: [10.027308, None]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-10cd5fe04919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_preprocess_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {:>2}, CIFAR-10 Batch {}: \\n '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-cafc27372ddd>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(session, optimizer, keep_probability, feature_batch, label_batch)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_feed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r ... this loss: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\xinyu\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mevt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\xinyu\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\xinyu\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}: \\n '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      " ... current loss: [2.9378459, None]\n",
      "Epoch  1, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 2.755 ... Validation accuracy: 0.102\n",
      " ... current loss: [3.0049424, None]\n",
      "Epoch  1, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 2.677 ... Validation accuracy: 0.097\n",
      " ... current loss: [2.6843579, None]\n",
      "Epoch  1, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 2.588 ... Validation accuracy: 0.106\n",
      " ... current loss: [2.255506, None]]\n",
      "Epoch  1, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 2.327 ... Validation accuracy: 0.106\n",
      " ... current loss: [2.4065824, None]\n",
      "Epoch  1, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 2.237 ... Validation accuracy: 0.189\n",
      " ... current loss: [2.2582207, None]\n",
      "Epoch  2, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 2.136 ... Validation accuracy: 0.250\n",
      " ... current loss: [2.1881499, None]\n",
      "Epoch  2, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 2.097 ... Validation accuracy: 0.244\n",
      " ... current loss: [2.1224799, None]\n",
      "Epoch  2, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 2.058 ... Validation accuracy: 0.273\n",
      " ... current loss: [2.0160909, None]\n",
      "Epoch  2, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 2.030 ... Validation accuracy: 0.294\n",
      " ... current loss: [2.1718934, None]\n",
      "Epoch  2, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 2.012 ... Validation accuracy: 0.294\n",
      " ... current loss: [2.2248082, None]\n",
      "Epoch  3, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.993 ... Validation accuracy: 0.306\n",
      " ... current loss: [2.0382979, None]\n",
      "Epoch  3, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.979 ... Validation accuracy: 0.303\n",
      " ... current loss: [1.9400402, None]\n",
      "Epoch  3, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.959 ... Validation accuracy: 0.322\n",
      " ... current loss: [1.9322555, None]\n",
      "Epoch  3, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.930 ... Validation accuracy: 0.34\n",
      " ... current loss: [2.0298419, None]\n",
      "Epoch  3, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.912 ... Validation accuracy: 0.343\n",
      " ... current loss: [2.0943077, None]\n",
      "Epoch  4, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.897 ... Validation accuracy: 0.35\n",
      " ... current loss: [1.9755074, None]\n",
      "Epoch  4, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.879 ... Validation accuracy: 0.352\n",
      " ... current loss: [1.8783772, None]\n",
      "Epoch  4, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.888 ... Validation accuracy: 0.315\n",
      " ... current loss: [1.8400227, None]\n",
      "Epoch  4, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.854 ... Validation accuracy: 0.365\n",
      " ... current loss: [1.904438, None]]\n",
      "Epoch  4, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.838 ... Validation accuracy: 0.366\n",
      " ... current loss: [2.1055675, None]\n",
      "Epoch  5, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.838 ... Validation accuracy: 0.364\n",
      " ... current loss: [1.9221157, None]\n",
      "Epoch  5, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.823 ... Validation accuracy: 0.366\n",
      " ... current loss: [1.8017685, None]\n",
      "Epoch  5, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.842 ... Validation accuracy: 0.338\n",
      " ... current loss: [1.8117977, None]\n",
      "Epoch  5, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.810 ... Validation accuracy: 0.375\n",
      " ... current loss: [1.9419391, None]\n",
      "Epoch  5, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.800 ... Validation accuracy: 0.378\n",
      " ... current loss: [2.0695939, None]\n",
      "Epoch  6, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.800 ... Validation accuracy: 0.376\n",
      " ... current loss: [1.8191574, None]\n",
      "Epoch  6, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.784 ... Validation accuracy: 0.378\n",
      " ... current loss: [1.6988392, None]\n",
      "Epoch  6, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.797 ... Validation accuracy: 0.368\n",
      " ... current loss: [1.7704494, None]\n",
      "Epoch  6, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.769 ... Validation accuracy: 0.380\n",
      " ... current loss: [1.9072956, None]\n",
      "Epoch  6, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.763 ... Validation accuracy: 0.394\n",
      " ... current loss: [2.039031, None]]\n",
      "Epoch  7, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.767 ... Validation accuracy: 0.377\n",
      " ... current loss: [1.7950685, None]\n",
      "Epoch  7, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.747 ... Validation accuracy: 0.387\n",
      " ... current loss: [1.6706574, None]\n",
      "Epoch  7, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.757 ... Validation accuracy: 0.387\n",
      " ... current loss: [1.6569277, None]\n",
      "Epoch  7, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.729 ... Validation accuracy: 0.396\n",
      " ... current loss: [1.8340647, None]\n",
      "Epoch  7, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.728 ... Validation accuracy: 0.403\n",
      " ... current loss: [1.9950966, None]\n",
      "Epoch  8, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.730 ... Validation accuracy: 0.39\n",
      " ... current loss: [1.6963665, None]\n",
      "Epoch  8, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.711 ... Validation accuracy: 0.398\n",
      " ... current loss: [1.6165504, None]\n",
      "Epoch  8, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.718 ... Validation accuracy: 0.398\n",
      " ... current loss: [1.6547095, None]\n",
      "Epoch  8, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.696 ... Validation accuracy: 0.405\n",
      " ... current loss: [1.8365053, None]\n",
      "Epoch  8, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.692 ... Validation accuracy: 0.416\n",
      " ... current loss: [1.8206968, None]\n",
      "Epoch  9, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.691 ... Validation accuracy: 0.410\n",
      " ... current loss: [1.6984189, None]\n",
      "Epoch  9, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.678 ... Validation accuracy: 0.404\n",
      " ... current loss: [1.5871565, None]\n",
      "Epoch  9, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.685 ... Validation accuracy: 0.410\n",
      " ... current loss: [1.5904739, None]\n",
      "Epoch  9, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.658 ... Validation accuracy: 0.419\n",
      " ... current loss: [1.8213829, None]\n",
      "Epoch  9, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.659 ... Validation accuracy: 0.427\n",
      " ... current loss: [1.9279867, None]\n",
      "Epoch 10, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.658 ... Validation accuracy: 0.424\n",
      " ... current loss: [1.6500906, None]\n",
      "Epoch 10, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.646 ... Validation accuracy: 0.417\n",
      " ... current loss: [1.5139446, None]\n",
      "Epoch 10, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.659 ... Validation accuracy: 0.420\n",
      " ... current loss: [1.5167192, None]\n",
      "Epoch 10, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.627 ... Validation accuracy: 0.434\n",
      " ... current loss: [1.7525795, None]\n",
      "Epoch 10, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.624 ... Validation accuracy: 0.436\n",
      " ... current loss: [1.8313767, None]\n",
      "Epoch 11, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.630 ... Validation accuracy: 0.432\n",
      " ... current loss: [1.5893933, None]\n",
      "Epoch 11, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.613 ... Validation accuracy: 0.432\n",
      " ... current loss: [1.436614, None]]\n",
      "Epoch 11, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.612 ... Validation accuracy: 0.435\n",
      " ... current loss: [1.5600803, None]\n",
      "Epoch 11, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.601 ... Validation accuracy: 0.439\n",
      " ... current loss: [1.7914623, None]\n",
      "Epoch 11, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.599 ... Validation accuracy: 0.442\n",
      " ... current loss: [1.8003094, None]\n",
      "Epoch 12, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.601 ... Validation accuracy: 0.441\n",
      " ... current loss: [1.6373451, None]\n",
      "Epoch 12, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.581 ... Validation accuracy: 0.443\n",
      " ... current loss: [1.4097664, None]\n",
      "Epoch 12, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.589 ... Validation accuracy: 0.447\n",
      " ... current loss: [1.4470745, None]\n",
      "Epoch 12, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.576 ... Validation accuracy: 0.451\n",
      " ... current loss: [1.6693709, None]\n",
      "Epoch 12, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.563 ... Validation accuracy: 0.451\n",
      " ... current loss: [1.7110323, None]\n",
      "Epoch 13, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.574 ... Validation accuracy: 0.448\n",
      " ... current loss: [1.5068527, None]\n",
      "Epoch 13, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.554 ... Validation accuracy: 0.452\n",
      " ... current loss: [1.2682014, None]\n",
      "Epoch 13, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.547 ... Validation accuracy: 0.462\n",
      " ... current loss: [1.4281473, None]\n",
      "Epoch 13, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.532 ... Validation accuracy: 0.457\n",
      " ... current loss: [1.614084, None]]\n",
      "Epoch 13, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.509 ... Validation accuracy: 0.471\n",
      " ... current loss: [1.7047096, None]\n",
      "Epoch 14, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.548 ... Validation accuracy: 0.456\n",
      " ... current loss: [1.4256884, None]\n",
      "Epoch 14, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.492 ... Validation accuracy: 0.477\n",
      " ... current loss: [1.2208939, None]\n",
      "Epoch 14, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.511 ... Validation accuracy: 0.469\n",
      " ... current loss: [1.3957222, None]\n",
      "Epoch 14, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.476 ... Validation accuracy: 0.474\n",
      " ... current loss: [1.5561244, None]\n",
      "Epoch 14, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.463 ... Validation accuracy: 0.491\n",
      " ... current loss: [1.685907, None]]\n",
      "Epoch 15, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.482 ... Validation accuracy: 0.475\n",
      " ... current loss: [1.3831222, None]\n",
      "Epoch 15, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.466 ... Validation accuracy: 0.482\n",
      " ... current loss: [1.1588987, None]\n",
      "Epoch 15, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.449 ... Validation accuracy: 0.493\n",
      " ... current loss: [1.2827429, None]\n",
      "Epoch 15, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.425 ... Validation accuracy: 0.492\n",
      " ... current loss: [1.5242345, None]\n",
      "Epoch 15, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.405 ... Validation accuracy: 0.510\n",
      " ... current loss: [1.6057904, None]\n",
      "Epoch 16, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.415 ... Validation accuracy: 0.502\n",
      " ... current loss: [1.2499501, None]\n",
      "Epoch 16, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.405 ... Validation accuracy: 0.506\n",
      " ... current loss: [1.0384061, None]\n",
      "Epoch 16, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.428 ... Validation accuracy: 0.496\n",
      " ... current loss: [1.3348119, None]\n",
      "Epoch 16, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.399 ... Validation accuracy: 0.504\n",
      " ... current loss: [1.3664981, None]\n",
      "Epoch 16, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.360 ... Validation accuracy: 0.526\n",
      " ... current loss: [1.6056519, None]\n",
      "Epoch 17, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.354 ... Validation accuracy: 0.521\n",
      " ... current loss: [1.2437643, None]\n",
      "Epoch 17, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.346 ... Validation accuracy: 0.523\n",
      " ... current loss: [1.1398393, None]\n",
      "Epoch 17, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.396 ... Validation accuracy: 0.505\n",
      " ... current loss: [1.2442468, None]\n",
      "Epoch 17, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.353 ... Validation accuracy: 0.522\n",
      " ... current loss: [1.4051231, None]\n",
      "Epoch 17, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.317 ... Validation accuracy: 0.538\n",
      " ... current loss: [1.5610162, None]\n",
      "Epoch 18, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.306 ... Validation accuracy: 0.541\n",
      " ... current loss: [1.1867874, None]\n",
      "Epoch 18, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.325 ... Validation accuracy: 0.536\n",
      " ... current loss: [1.0488622, None]\n",
      "Epoch 18, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.355 ... Validation accuracy: 0.518\n",
      " ... current loss: [1.1603966, None]\n",
      "Epoch 18, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.308 ... Validation accuracy: 0.533\n",
      " ... current loss: [1.3088529, None]\n",
      "Epoch 18, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.287 ... Validation accuracy: 0.548\n",
      " ... current loss: [1.489073, None]]\n",
      "Epoch 19, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.286 ... Validation accuracy: 0.549\n",
      " ... current loss: [1.0930734, None]\n",
      "Epoch 19, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.316 ... Validation accuracy: 0.539\n",
      " ... current loss: [0.92002279, None]\n",
      "Epoch 19, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.275 ... Validation accuracy: 0.550\n",
      " ... current loss: [1.1200117, None]\n",
      "Epoch 19, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.267 ... Validation accuracy: 0.557\n",
      " ... current loss: [1.2315401, None]]\n",
      "Epoch 19, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.262 ... Validation accuracy: 0.558\n",
      " ... current loss: [1.4250613, None]\n",
      "Epoch 20, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.255 ... Validation accuracy: 0.558\n",
      " ... current loss: [0.99075174, None]\n",
      "Epoch 20, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.297 ... Validation accuracy: 0.543\n",
      " ... current loss: [0.9371177, None]\n",
      "Epoch 20, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.268 ... Validation accuracy: 0.551\n",
      " ... current loss: [1.0632699, None]\n",
      "Epoch 20, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.233 ... Validation accuracy: 0.566\n",
      " ... current loss: [1.1249701, None]]\n",
      "Epoch 20, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.237 ... Validation accuracy: 0.567\n",
      " ... current loss: [1.5041463, None]\n",
      "Epoch 21, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.225 ... Validation accuracy: 0.57\n",
      " ... current loss: [0.95315951, None]\n",
      "Epoch 21, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.269 ... Validation accuracy: 0.556\n",
      " ... current loss: [0.83708459, None]\n",
      "Epoch 21, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.239 ... Validation accuracy: 0.562\n",
      " ... current loss: [1.0604204, None]]\n",
      "Epoch 21, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.213 ... Validation accuracy: 0.574\n",
      " ... current loss: [1.1606055, None]]\n",
      "Epoch 21, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.232 ... Validation accuracy: 0.568\n",
      " ... current loss: [1.3296146, None]]\n",
      "Epoch 22, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.222 ... Validation accuracy: 0.572\n",
      " ... current loss: [0.98775756, None]\n",
      "Epoch 22, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.279 ... Validation accuracy: 0.552\n",
      " ... current loss: [0.80581522, None]\n",
      "Epoch 22, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.234 ... Validation accuracy: 0.574\n",
      " ... current loss: [1.0436511, None]]\n",
      "Epoch 22, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.209 ... Validation accuracy: 0.576\n",
      " ... current loss: [1.1600537, None]]\n",
      "Epoch 22, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.212 ... Validation accuracy: 0.575\n",
      " ... current loss: [1.3352256, None]]\n",
      "Epoch 23, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.203 ... Validation accuracy: 0.578\n",
      " ... current loss: [0.89923048, None]\n",
      "Epoch 23, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.216 ... Validation accuracy: 0.572\n",
      " ... current loss: [0.78459865, None]\n",
      "Epoch 23, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.246 ... Validation accuracy: 0.565\n",
      " ... current loss: [1.0108745, None]]\n",
      "Epoch 23, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.193 ... Validation accuracy: 0.577\n",
      " ... current loss: [0.9947561, None]]\n",
      "Epoch 23, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.188 ... Validation accuracy: 0.586\n",
      " ... current loss: [1.2456758, None]]\n",
      "Epoch 24, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.193 ... Validation accuracy: 0.584\n",
      " ... current loss: [0.85540724, None]\n",
      "Epoch 24, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.200 ... Validation accuracy: 0.578\n",
      " ... current loss: [0.77811641, None]\n",
      "Epoch 24, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.216 ... Validation accuracy: 0.580\n",
      " ... current loss: [0.97521877, None]\n",
      "Epoch 24, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.170 ... Validation accuracy: 0.587\n",
      " ... current loss: [1.0096411, None]]\n",
      "Epoch 24, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.183 ... Validation accuracy: 0.581\n",
      " ... current loss: [1.1510768, None]]\n",
      "Epoch 25, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.194 ... Validation accuracy: 0.583\n",
      " ... current loss: [0.86904871, None]\n",
      "Epoch 25, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.191 ... Validation accuracy: 0.578\n",
      " ... current loss: [0.74629295, None]\n",
      "Epoch 25, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.192 ... Validation accuracy: 0.588\n",
      " ... current loss: [0.9758873, None]]\n",
      "Epoch 25, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.587\n",
      " ... current loss: [0.97609842, None]\n",
      "Epoch 25, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.589\n",
      " ... current loss: [1.1462311, None]]\n",
      "Epoch 26, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.587\n",
      " ... current loss: [0.81406081, None]\n",
      "Epoch 26, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.187 ... Validation accuracy: 0.587\n",
      " ... current loss: [0.74678636, None]\n",
      "Epoch 26, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.180 ... Validation accuracy: 0.588\n",
      " ... current loss: [1.0012352, None]]\n",
      "Epoch 26, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.154 ... Validation accuracy: 0.598\n",
      " ... current loss: [0.93545169, None]\n",
      "Epoch 26, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.59\n",
      " ... current loss: [1.1856295, None]]\n",
      "Epoch 27, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.164 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.794963, None]e]\n",
      "Epoch 27, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.196 ... Validation accuracy: 0.577\n",
      " ... current loss: [0.62702787, None]\n",
      "Epoch 27, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.164 ... Validation accuracy: 0.590\n",
      " ... current loss: [0.84966052, None]\n",
      "Epoch 27, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.150 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.89384687, None]\n",
      "Epoch 27, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.170 ... Validation accuracy: 0.593\n",
      " ... current loss: [1.0621951, None]]\n",
      "Epoch 28, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.167 ... Validation accuracy: 0.594\n",
      " ... current loss: [0.7124486, None]]\n",
      "Epoch 28, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.172 ... Validation accuracy: 0.586\n",
      " ... current loss: [0.71211469, None]\n",
      "Epoch 28, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.149 ... Validation accuracy: 0.602\n",
      " ... current loss: [0.85951293, None]\n",
      "Epoch 28, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.169 ... Validation accuracy: 0.591\n",
      " ... current loss: [0.89662886, None]\n",
      "Epoch 28, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.177 ... Validation accuracy: 0.590\n",
      " ... current loss: [1.0941515, None]]\n",
      "Epoch 29, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.168 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.66342628, None]\n",
      "Epoch 29, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.172 ... Validation accuracy: 0.593\n",
      " ... current loss: [0.6960097, None]]\n",
      "Epoch 29, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.171 ... Validation accuracy: 0.593\n",
      " ... current loss: [0.83241367, None]\n",
      "Epoch 29, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.185 ... Validation accuracy: 0.591\n",
      " ... current loss: [0.79985631, None]\n",
      "Epoch 29, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.187 ... Validation accuracy: 0.59\n",
      " ... current loss: [1.1231806, None]]\n",
      "Epoch 30, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.175 ... Validation accuracy: 0.587\n",
      " ... current loss: [0.63586992, None]\n",
      "Epoch 30, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.205 ... Validation accuracy: 0.585\n",
      " ... current loss: [0.62888449, None]\n",
      "Epoch 30, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.181 ... Validation accuracy: 0.592\n",
      " ... current loss: [0.80502015, None]\n",
      "Epoch 30, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.183 ... Validation accuracy: 0.593\n",
      " ... current loss: [0.89832211, None]\n",
      "Epoch 30, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.183 ... Validation accuracy: 0.594\n",
      " ... current loss: [0.99261284, None]\n",
      "Epoch 31, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.163 ... Validation accuracy: 0.597\n",
      " ... current loss: [0.63161659, None]\n",
      "Epoch 31, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.206 ... Validation accuracy: 0.581\n",
      " ... current loss: [0.66724527, None]\n",
      "Epoch 31, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.168 ... Validation accuracy: 0.589\n",
      " ... current loss: [0.75593328, None]\n",
      "Epoch 31, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.174 ... Validation accuracy: 0.597\n",
      " ... current loss: [0.79950887, None]\n",
      "Epoch 31, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.155 ... Validation accuracy: 0.603\n",
      " ... current loss: [1.0382007, None]]\n",
      "Epoch 32, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.191 ... Validation accuracy: 0.586\n",
      " ... current loss: [0.59058988, None]\n",
      "Epoch 32, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.184 ... Validation accuracy: 0.588\n",
      " ... current loss: [0.58631814, None]\n",
      "Epoch 32, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.169 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.69164008, None]\n",
      "Epoch 32, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.189 ... Validation accuracy: 0.589\n",
      " ... current loss: [0.75657606, None]\n",
      "Epoch 32, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.165 ... Validation accuracy: 0.603\n",
      " ... current loss: [0.93303794, None]\n",
      "Epoch 33, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.594\n",
      " ... current loss: [0.53354561, None]\n",
      "Epoch 33, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.183 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.51687056, None]\n",
      "Epoch 33, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.72220838, None]\n",
      "Epoch 33, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.179 ... Validation accuracy: 0.594\n",
      " ... current loss: [0.69535816, None]\n",
      "Epoch 33, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.166 ... Validation accuracy: 0.604\n",
      " ... current loss: [0.88188422, None]\n",
      "Epoch 34, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.162 ... Validation accuracy: 0.602\n",
      " ... current loss: [0.63204944, None]\n",
      "Epoch 34, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.192 ... Validation accuracy: 0.586\n",
      " ... current loss: [0.47060385, None]\n",
      "Epoch 34, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.598\n",
      " ... current loss: [0.60517704, None]\n",
      "Epoch 34, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.178 ... Validation accuracy: 0.597\n",
      " ... current loss: [0.68572873, None]\n",
      "Epoch 34, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.170 ... Validation accuracy: 0.605\n",
      " ... current loss: [0.91715944, None]\n",
      "Epoch 35, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.182 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.56765258, None]\n",
      "Epoch 35, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.187 ... Validation accuracy: 0.587\n",
      " ... current loss: [0.48106614, None]\n",
      "Epoch 35, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.166 ... Validation accuracy: 0.601\n",
      " ... current loss: [0.62679189, None]\n",
      "Epoch 35, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.180 ... Validation accuracy: 0.598\n",
      " ... current loss: [0.55692273, None]\n",
      "Epoch 35, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.171 ... Validation accuracy: 0.605\n",
      " ... current loss: [0.77900249, None]\n",
      "Epoch 36, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.181 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.5508669, None]]\n",
      "Epoch 36, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.591\n",
      " ... current loss: [0.47761631, None]\n",
      "Epoch 36, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.180 ... Validation accuracy: 0.594\n",
      " ... current loss: [0.49991655, None]\n",
      "Epoch 36, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.172 ... Validation accuracy: 0.600\n",
      " ... current loss: [0.59230077, None]\n",
      "Epoch 36, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.172 ... Validation accuracy: 0.604\n",
      " ... current loss: [0.77872795, None]\n",
      "Epoch 37, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.166 ... Validation accuracy: 0.604\n",
      " ... current loss: [0.52758712, None]\n",
      "Epoch 37, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.156 ... Validation accuracy: 0.598\n",
      " ... current loss: [0.49218148, None]\n",
      "Epoch 37, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.176 ... Validation accuracy: 0.597\n",
      " ... current loss: [0.50982362, None]\n",
      "Epoch 37, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.175 ... Validation accuracy: 0.599\n",
      " ... current loss: [0.52627999, None]\n",
      "Epoch 37, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.190 ... Validation accuracy: 0.603\n",
      " ... current loss: [0.8408348, None]]\n",
      "Epoch 38, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.607\n",
      " ... current loss: [0.47746569, None]\n",
      "Epoch 38, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.156 ... Validation accuracy: 0.605\n",
      " ... current loss: [0.47436935, None]\n",
      "Epoch 38, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.155 ... Validation accuracy: 0.608\n",
      " ... current loss: [0.55198795, None]\n",
      "Epoch 38, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.193 ... Validation accuracy: 0.597\n",
      " ... current loss: [0.50306064, None]\n",
      "Epoch 38, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.187 ... Validation accuracy: 0.605\n",
      " ... current loss: [0.76529098, None]\n",
      "Epoch 39, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.178 ... Validation accuracy: 0.601\n",
      " ... current loss: [0.45191002, None]\n",
      "Epoch 39, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.185 ... Validation accuracy: 0.592\n",
      " ... current loss: [0.418046, None]e]\n",
      "Epoch 39, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.152 ... Validation accuracy: 0.604\n",
      " ... current loss: [0.51875782, None]\n",
      "Epoch 39, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.210 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.45670342, None]\n",
      "Epoch 39, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.190 ... Validation accuracy: 0.603\n",
      " ... current loss: [0.68686581, None]\n",
      "Epoch 40, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.181 ... Validation accuracy: 0.603\n",
      " ... current loss: [0.48668319, None]\n",
      "Epoch 40, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.180 ... Validation accuracy: 0.598\n",
      " ... current loss: [0.4060058, None]]\n",
      "Epoch 40, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.199 ... Validation accuracy: 0.589\n",
      " ... current loss: [0.48304349, None]\n",
      "Epoch 40, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.197 ... Validation accuracy: 0.594\n",
      " ... current loss: [0.54975718, None]\n",
      "Epoch 40, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.231 ... Validation accuracy: 0.59\n",
      " ... current loss: [0.78020972, None]\n",
      "Epoch 41, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.169 ... Validation accuracy: 0.604\n",
      " ... current loss: [0.46427184, None]\n",
      "Epoch 41, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.169 ... Validation accuracy: 0.600\n",
      " ... current loss: [0.38212019, None]\n",
      "Epoch 41, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.184 ... Validation accuracy: 0.600\n",
      " ... current loss: [0.43312415, None]\n",
      "Epoch 41, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.209 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.48311862, None]\n",
      "Epoch 41, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.206 ... Validation accuracy: 0.605\n",
      " ... current loss: [0.7854861, None]]\n",
      "Epoch 42, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.195 ... Validation accuracy: 0.606\n",
      " ... current loss: [0.43819323, None]\n",
      "Epoch 42, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.194 ... Validation accuracy: 0.594\n",
      " ... current loss: [0.35387444, None]\n",
      "Epoch 42, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.193 ... Validation accuracy: 0.603\n",
      " ... current loss: [0.47759828, None]\n",
      "Epoch 42, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.215 ... Validation accuracy: 0.599\n",
      " ... current loss: [0.43820149, None]\n",
      "Epoch 42, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.241 ... Validation accuracy: 0.589\n",
      " ... current loss: [0.69499749, None]\n",
      "Epoch 43, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.191 ... Validation accuracy: 0.602\n",
      " ... current loss: [0.47334021, None]\n",
      "Epoch 43, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.194 ... Validation accuracy: 0.599\n",
      " ... current loss: [0.33741274, None]\n",
      "Epoch 43, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.187 ... Validation accuracy: 0.604\n",
      " ... current loss: [0.35111195, None]\n",
      "Epoch 43, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.220 ... Validation accuracy: 0.6\n",
      " ... current loss: [0.53932029, None]\n",
      "Epoch 43, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.212 ... Validation accuracy: 0.603\n",
      " ... current loss: [0.71833074, None]\n",
      "Epoch 44, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.216 ... Validation accuracy: 0.598\n",
      " ... current loss: [0.39311951, None]\n",
      "Epoch 44, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.191 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.33003083, None]\n",
      "Epoch 44, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.173 ... Validation accuracy: 0.606\n",
      " ... current loss: [0.43877363, None]\n",
      "Epoch 44, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.206 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.40553489, None]\n",
      "Epoch 44, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.186 ... Validation accuracy: 0.605\n",
      " ... current loss: [0.72148764, None]\n",
      "Epoch 45, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.190 ... Validation accuracy: 0.607\n",
      " ... current loss: [0.4864915, None]]\n",
      "Epoch 45, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.199 ... Validation accuracy: 0.594\n",
      " ... current loss: [0.41089684, None]\n",
      "Epoch 45, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.181 ... Validation accuracy: 0.601\n",
      " ... current loss: [0.38011089, None]\n",
      "Epoch 45, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.215 ... Validation accuracy: 0.607\n",
      " ... current loss: [0.40627617, None]\n",
      "Epoch 45, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.195 ... Validation accuracy: 0.605\n",
      " ... current loss: [0.67061424, None]\n",
      "Epoch 46, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.212 ... Validation accuracy: 0.597\n",
      " ... current loss: [0.37873143, None]\n",
      "Epoch 46, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.196 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.39006194, None]\n",
      "Epoch 46, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.180 ... Validation accuracy: 0.603\n",
      " ... current loss: [0.37157497, None]\n",
      "Epoch 46, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.226 ... Validation accuracy: 0.599\n",
      " ... current loss: [0.41267747, None]\n",
      "Epoch 46, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.231 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.66908216, None]\n",
      "Epoch 47, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.212 ... Validation accuracy: 0.602\n",
      " ... current loss: [0.42488804, None]\n",
      "Epoch 47, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.223 ... Validation accuracy: 0.588\n",
      " ... current loss: [0.30218574, None]\n",
      "Epoch 47, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.209 ... Validation accuracy: 0.600\n",
      " ... current loss: [0.3782829, None]]\n",
      "Epoch 47, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.263 ... Validation accuracy: 0.592\n",
      " ... current loss: [0.36503774, None]\n",
      "Epoch 47, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.255 ... Validation accuracy: 0.592\n",
      " ... current loss: [0.57920271, None]\n",
      "Epoch 48, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.241 ... Validation accuracy: 0.589\n",
      " ... current loss: [0.43250903, None]\n",
      "Epoch 48, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.239 ... Validation accuracy: 0.586\n",
      " ... current loss: [0.32601708, None]\n",
      "Epoch 48, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.212 ... Validation accuracy: 0.602\n",
      " ... current loss: [0.32469976, None]\n",
      "Epoch 48, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.272 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.38463846, None]\n",
      "Epoch 48, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.229 ... Validation accuracy: 0.598\n",
      " ... current loss: [0.61049521, None]\n",
      "Epoch 49, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.226 ... Validation accuracy: 0.600\n",
      " ... current loss: [0.395154, None]e]\n",
      "Epoch 49, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.216 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.4288559, None]]\n",
      "Epoch 49, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.201 ... Validation accuracy: 0.604\n",
      " ... current loss: [0.36381835, None]\n",
      "Epoch 49, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.297 ... Validation accuracy: 0.590\n",
      " ... current loss: [0.37442029, None]\n",
      "Epoch 49, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.228 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.60971755, None]\n",
      "Epoch 50, CIFAR-10 Batch 1: \n",
      " ...Validation loss: 1.244 ... Validation accuracy: 0.592\n",
      " ... current loss: [0.2985788, None]]\n",
      "Epoch 50, CIFAR-10 Batch 2: \n",
      " ...Validation loss: 1.222 ... Validation accuracy: 0.596\n",
      " ... current loss: [0.34343415, None]\n",
      "Epoch 50, CIFAR-10 Batch 3: \n",
      " ...Validation loss: 1.193 ... Validation accuracy: 0.600\n",
      " ... current loss: [0.31288451, None]\n",
      "Epoch 50, CIFAR-10 Batch 4: \n",
      " ...Validation loss: 1.282 ... Validation accuracy: 0.595\n",
      " ... current loss: [0.32730579, None]\n",
      "Epoch 50, CIFAR-10 Batch 5: \n",
      " ...Validation loss: 1.245 ... Validation accuracy: 0.603\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('\\nEpoch {:>2}, CIFAR-10 Batch {}: \\n '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5931566455696202\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAIABJREFUeJzs3XecZFWZ//HP03G6e2Z6MgxxyAxRHUEwwGDYVdkVdFXM\ngmtEMKfV3Z+wrqtrRDGtAVlzDmt2RUBEESU6ZEYGmADD5Onp3P38/nhO1b19p7q6eqbDdM/3/XrV\nq7ruuffcc6urq5869ZxzzN0RERERERGom+wGiIiIiIjsKRQci4iIiIgkCo5FRERERBIFxyIiIiIi\niYJjEREREZFEwbGIiIiISKLgWEREREQkUXAsIiIiIpIoOBYRERERSRQci4iIiIgkCo5FRERERBIF\nxyIiIiIiiYJjEREREZFEwbGIiIiISKLgeJKZ2cFm9hwze52Z/YuZvcvMLjSz55nZY81s5mS3cThm\nVmdmZ5nZt8zsXjPbZmaeu/1ostsosqcxsyWFv5OLxmLfPZWZLS9cw7mT3SYRkWoaJrsBeyMzmwe8\nDngVcPAIuw+a2e3ANcDPgCvcvXucmziidA3fA86Y7LbIxDOzy4GXj7BbP7AF2ADcSLyGv+nuW8e3\ndSIiIrtOPccTzMz+Abgd+A9GDowhfkfHEcH0T4Hnjl/rRuUrjCIwVu/RXqkBWAAcDbwI+Cywxswu\nMjN9MJ9CCn+7l092e0RExpP+QU0gM3s+8E12/lCyDfgr8BDQA8wFDgKWVth30pnZKcCZuU33AxcD\nfwG257Z3TmS7ZEpoA94LnGZmz3D3nslukIiISJ6C4wliZocRva35YHcF8B7g5+7eX+GYmcDpwPOA\nZwOzJ6CptXhO4fFZ7n7LpLRE9hRvJ9Js8hqAfYAnAucTH/hKziB6kl8xIa0TERGpkYLjifN+oDn3\n+DfAs9y9a7gD3L2DyDP+mZldCLyS6F2ebMtyP69SYCzABndfVWH7vcC1ZnYp8DXiQ17JuWb2SXe/\neSIaOBWl59Qmux27w92vYopfg4jsXfa4r+ynIzNrAZ6V29QHvLxaYFzk7tvd/ePu/psxb+DoLcr9\nvHbSWiFThrt3Ai8G7s5tNuC1k9MiERGRyhQcT4zHAC25x39w96kcVOanl+ubtFbIlJI+DH68sPkp\nk9EWERGR4SitYmLsW3i8ZiJPbmazgScB+wPziUFzDwN/cvcHdqXKMWzemDCzQ4l0jwOAJmAVcKW7\nrx/huAOInNgDietal45bvRtt2R84FjgUmJM2bwIeAP64l09ldkXh8WFmVu/uA6OpxMyOA44BFhOD\n/Fa5+zdqOK4JOBVYQnwDMgisB24di/QgMzsCOBnYD+gGVgPXu/uE/s1XaNeRwKOAhcRrspN4ra8A\nbnf3wUls3ojM7EDgFCKHfRbx97QWuMbdt4zxuQ4lOjQOBOqJ98pr3f1vu1HnUcTzvy/RudAPdAAP\nAvcAd7q772bTRWSsuLtu43wDXgB47vaLCTrvY4FfAL2F8+dvtxLTbFmVepZXOX6421Xp2FW7emyh\nDZfn98ltPx24kghyivX0Ap8BZlao7xjg58McNwh8H9i/xue5LrXjs8DKEa5tAPg/4Iwa6/6fwvGf\nH8Xv/wOFY39S7fc8ytfW5YW6z63xuJYKz8miCvvlXzdX5bafRwR0xTq2jHDeo4BvEB8Mh/vdrAbe\nAjTtwvPxBOBPw9TbT4wdWJb2XVIov6hKvTXvW+HYOcD7iA9l1V6TjwCXASeN8Duu6VbD+0dNr5V0\n7POBm6ucry/9PZ0yijqvyh2/Krf9ccSHt0rvCQ5cB5w6ivM0Am8l8u5Het62EO85TxuLv0/ddNNt\n926T3oC94QY8ufBGuB2YM47nM+BDVd7kK92uAuYOU1/xn1tN9aVjV+3qsYU2DPlHnba9ocZr/DO5\nAJmYbaOzhuNWAQfW8Hy/Yheu0YGPAvUj1N0G3Fk47pwa2vR3hedmNTB/DF9jlxfadG6Nx+1ScEwM\nZv1OleeyYnBM/C38OxFE1fp7WVHL7z13jnfX+DrsJfKulxS2X1Sl7pr3LRz3bGDzKF+PN4/wO67p\nVsP7x4ivFWJmnt+M8tyXAHU11H1V7phVaduFVO9EyP8On1/DORYSC9+M9vn70Vj9jeqmm267flNa\nxcS4gegxrE+PZwJfMbMXecxIMda+APxzYVsv0fOxluhReiyxQEPJ6cDvzOw0d988Dm0aU2nO6E+k\nh070Lq0kgqFHAYfldn8scClwnpmdAXybLKXoznTrJeaVPj533MHUtthJMXe/C7iN+Np6GxEQHgSc\nQKR8lLyFCNreNVzF7r4jXeufgBlp8+fN7C/uvrLSMWa2L/BVsvSXAeBF7r5xhOuYCPsXHjtQS7su\nIaY0LB1zE1kAfShwSPEAMzOi5/2lhaIuInAp5f0fTrxmSs/XscAfzOwkd686O4yZvYmYiSZvgPh9\nPUikADyaSP9oJALO4t/mmEpt+hg7pz89RHxTtAFoJVKQjmfoLDqTzsxmAVcTv5O8zcD16X4xkWaR\nb/sbife0l4zyfC8BPpnbtILo7e0h3keWkT2XjcDlZnaTu98zTH0G/ID4vec9TMxnv4H4MNWe6j8c\npTiK7FkmOzrfW27E6nbFXoK1xIIIxzN2X3e/vHCOQSKwmFPYr4H4J721sP83K9Q5g+jBKt1W5/a/\nrlBWuu2bjj0gPS6mlrxtmOPKxxbacHnh+FKv2E+Bwyrs/3wiCMo/D6em59yBPwCPqnDcciJYy5/r\nmSM856Up9j6QzlGxN5j4UPJOYEehXY+r4ff62kKb/kKFr/+JQL3Y4/Zv4/B6Lv4+zq3xuFcXjrt3\nmP1W5fbJp0J8FTigwv5LKmx7V+Fcm9LzOKPCvocAPy7s/yuqpxsdz869jd8ovn7T7+T5RG5zqR35\nYy6qco4lte6b9v97IjjPH3M18PhK10IEl/9IfKV/Q6FsAdnfZL6+7zH8326l38Py0bxWgC8X9t8G\nvAZoLOzXTnz7Uuy1f80I9V+V27eD7H3ih8DhFfZfCtxSOMe3q9R/ZmHfe4iBpxVfS8S3Q2cB3wK+\nO9Z/q7rpptvob5PegL3lRvSCdBfeNPO3jURe4r8BTwPaduEcM4nctXy9bx7hmMcxNFhzRsh7Y5h8\n0BGOGdU/yArHX17hOfs6Vb5GJZbcrhRQ/wZornLcP9T6jzDtv2+1+irsf2rhtVC1/txxxbSCT1TY\n5z2Ffa6o9hztxuu5+PsY8fdJfMi6o3BcxRxqKqfjfGAU7TuWoakUD1IhcCscY0Tubf6cZ1bZ/8rC\nvp+qoU3FwHjMgmOiN/jhYptq/f0D+1Qpy9d5+ShfKzX/7RMDh/P7dgJPGKH+CwrHdDBMilja/6oK\nv4NPUf2D0D4MTVPpHu4cxNiD0n59wCGjeK52+uCmm266TfxNU7lNEI+FDl5KvKlWMg94JpEf+Wtg\ns5ldY2avSbNN1OLlRG9KyS/dvTh1VrFdfwL+X2HzG2s832RaS/QQVRtl/yWiZ7ykNEr/pV5l2WJ3\n/ylwV27T8moNcfeHqtVXYf8/Ap/ObTrbzGr5avuVQH7E/BvM7KzSAzN7IrGMd8kjwEtGeI4mhJnN\nIHp9jy4U/XeNVdwM/OsoTvkOsq+qHXieV16kpMzdnVjJLz9TScW/BTM7lqGvi7uJNJlq9d+W2jVe\nXsXQOcivBC6s9ffv7g+PS6tG5w2Fxxe7+7XVDnD3TxHfIJW0MbrUlRVEJ4JXOcfDRNBb0kykdVSS\nXwnyZne/r9aGuPtw/x9EZAIpOJ5A7v5d4uvN39eweyMxxdjngL+Z2fkpl62aFxcev7fGpn2SCKRK\nnmlm82o8drJ83kfI13b3XqD4j/Vb7r6uhvp/m/t5UcrjHUs/zv3cxM75lTtx923AOcRX+SVfNrOD\nzGw+8E2yvHYHXlbjtY6FBWa2pHA73Mweb2bvAG4Hnls45uvufkON9V/iNU73ZmZzgBfmNv3M3a+r\n5dgUnHw+t+kMM2utsGvxb+1D6fU2kssYv6kcX1V4XDXg29OYWRtwdm7TZiIlrBbFD06jyTv+uLvX\nMl/7zwuPT6zhmIWjaIeI7CEUHE8wd7/J3Z8EnEb0bFadhzeZT/Q0fivN07qT1POYX9b5b+5+fY1t\n6gO+m6+O4XtF9hS/rnG/4qC1/6vxuHsLj0f9T87CLDPbrxg4svNgqWKPakXu/hcib7lkLhEUX07k\nd5d82N1/Odo274YPA/cVbvcQH07+i50HzF3LzsFcNT8Zxb5PID5clnxvFMcCXJP7uYFIPSo6Nfdz\naeq/EaVe3O+OuOMomdlCIm2j5M8+9ZZ1P4mhA9N+WOs3Mulab89tOj4N7KtFrX8ndxYeD/eekP/W\n6WAze32N9YvIHkIjZCeJu19D+idsZscQPcrLiH8QjyLrAcx7PjHSudKb7XEMnQnhT6Ns0nXEV8ol\ny9i5p2RPUvxHNZxthcd3Vdxr5ONGTG0xs3rgqcSsCicRAW/FDzMVzK1xP9z9kjTrRmlJ8scXdrmO\nyD3eE3URs4z8vxp76wAecPdNozjHEwqPN6YPJLUq/u1VOvYxuZ/v8dEtRPHnUexbq2IAf03FvfZs\nywqPd+U97Jj0cx3xPjrS87DNa1+ttLh4z3DvCd8C3px7/CkzO5sYaPgLnwKzAYns7RQc7wHc/Xai\n1+OLAGbWTsxT+iZ2/urufDP7krvfWNhe7MWoOM1QFcWgcU//OrDWVeb6x+i4xop7JWZ2KpE/e3y1\n/aqoNa+85DxiOrODCtu3AC9092L7J8MA8XxvJNp6DfCNUQa6MDTlpxYHFB6Ppte5kiEpRil/Ov/7\nqjilXhXFbyXGQjHt545xOMd4m4z3sJpXq3T3vkJmW8X3BHe/3sw+w9DOhqem26CZ/ZX45uR31LCK\np4hMPKVV7IHcfau7X07Mk3lxhV2Kg1YgW6a4pNjzOZLiP4maezInw24MMhvzwWlm9nRi8NOuBsYw\nyr/FFGD+Z4Wit4408GycnOfuVrg1uPt8dz/S3c9x90/tQmAMMfvAaIx1vvzMwuOx/lsbC/MLj8d0\nSeUJMhnvYeM1WPUC4tubzsL2OqLD43yih3mdmV1pZs+tYUyJiEwQBcd7MA8XEYtW5D11EpojFaSB\ni19j6GIEq4hle59BLFs8h5iiqRw4UmHRilGedz4x7V/RS8xsb/+7rtrLvwumYtAyZQbiTUfpvfs/\niQVq3gn8kZ2/jYL4H7ycyEO/2swWT1gjRWRYSquYGi4lZiko2d/MWty9K7et2FM02q/p2wuPlRdX\nm/MZ2mv3LeDlNcxcUOtgoZ3kVn4rrjYHsZrfvxJTAu6tir3Tx7j7WKYZjPXf2lgoXnOxF3YqmHbv\nYWkKuA8BHzKzmcDJxFzOZxC58fn/wU8CfmlmJ49makgRGXt7ew/TVFFp1HnxK8NiXubhozzHkSPU\nJ5Wdmft5K/DKGqf02p2p4d5cOO/1DJ315P+Z2ZN2o/6prpjDuaDiXrsoTfeW/8r/sOH2HcZo/zZr\nUVzmeuk4nGO8Tev3MHfvcPffuvvF7r6cWAL7X4lBqiUnAK+YjPaJSEbB8dRQKS+umI+3gqHz3548\nynMUp26rdf7ZWk3Xr3nz/8B/7+47ajxul6bKM7OTgA/mNm0mZsd4GdlzXA98I6Ve7I2KcxpXmopt\nd+UHxB6R5lau1Ulj3Rh2vuap+OGo+J4z2t9b/m9qkFg4Zo/l7hvc/f3sPKXhP05Ge0Qko+B4ajiq\n8LijuABG+hou/8/lcDMrTo1UkZk1EAFWuTpGP43SSIpfE9Y6xdmeLv9Vbk0DiFJaxItGe6K0UuK3\nGJpT+wp3f8Ddf0XMNVxyADF11N7otwz9MPb8cTjHH3M/1wH/VMtBKR/8eSPuOEru/gjxAbnkZDPb\nnQGiRfm/3/H62/0zQ/Nynz3cvO5FZnYCQ+d5XuHu28eycePo2wx9fpdMUjtEJFFwPAHMbB8z22c3\nqih+zXbVMPt9o/C4uCz0cC5g6LKzv3D3jTUeW6viSPKxXnFusuTzJItf6w7npdS46EfBF4gBPiWX\nuvuPco/fw9APNf9oZlNhKfAxlfI888/LSWY21gHp1wuP31FjIPcKKueKj4XPFx5/bAxnQMj//Y7L\n32761iW/cuQ8Ks/pXkkxx/5rY9KoCZCmXcx/41RLWpaIjCMFxxNjKbEE9AfNbNGIe+eY2T8Bryts\nLs5eUfI/DP0n9iwzO3+YfUv1n0TMrJD3ydG0sUZ/Y2iv0BnjcI7J8Nfcz8vM7PRqO5vZycQAy1Ex\ns1cztAf0JuDt+X3SP9kXMPQ18CEzyy9Ysbf4d4amI1020u+myMwWm9kzK5W5+23A1blNRwIfG6G+\nY4jBWePlS8DDucdPBT5ea4A8wgf4/BzCJ6XBZeOh+N7zvvQeNSwzex1wVm7TDuK5mBRm9jozqznP\n3cyewdDpB2tdqEhExomC44nTSkzps9rMfmhm/5SWfK3IzJaa2eeB7zB0xa4b2bmHGID0NeJbCpsv\nNbMPp4VF8vU3mNl5xHLK+X9030lf0Y+plPaR79VcbmZfNLOnmNkRheWVp1KvcnFp4u+b2bOKO5lZ\ni5m9GbiCGIW/odYTmNlxwCW5TR3AOZVGtKc5jl+Z29RELDs+XsHMHsndbyYGO5XMBK4ws0+a2bAD\n6Mxsjpk938y+TUzJ97Iqp7kQyK/y93oz+3rx9Wtmdann+ipiIO24zEHs7p1Ee/MfCt5IXPeplY4x\ns2Yz+wcz+z7VV8T8Xe7nmcDPzOzZ6X2quDT67lzD74Cv5ja1Af9nZv+c0r/ybZ9tZh8CPlWo5u27\nOJ/2WHkncL+ZfSU9t22VdkrvwS8jln/PmzK93iLTlaZym3iNwNnphpndCzxABEuDxD/PY4ADKxy7\nGnhetQUw3P0yMzsNeHnaVAe8DbjQzP4IrCOmeTqJnUfx387OvdRj6VKGLu37z+lWdDUx9+dUcBkx\ne8QR6fF84Mdmdj/xQaab+Br6ccQHJIjR6a8j5jatysxaiW8KWnKbX+vuw64e5u7fM7PPAa9Nm44A\nPge8pMZrmhbc/QMpWHt12lRPBLQXmtl9xBLkm4m/yTnE87RkFPX/1czeydAe4xcB55jZdcCDRCC5\njJiZAOLbkzczTvng7v5rM3sb8FGy+ZnPAP5gZuuAW4kVC1uIvPQTyOborjQrTskXgbcCM9Lj09Kt\nkt1N5biAWCjjhPS4PZ3/v8zseuLDxb7Aqbn2lHzL3T+7m+cfC61E+tRLiVXx7iI+bJU+GC0mFnkq\nTj/3I3ff3RUdRWQ3KTieGJuI4LfSV22HU9uURb8BXlXj6mfnpXO+iewfVTPVA87fA2eNZ4+Lu3/b\nzB5HBAfTgrv3pJ7i35IFQAAHp1tRBzEg684aT3Ep8WGp5MvuXsx3reTNxAeR0qCsF5vZFe6+Vw3S\nc/fXmNmtxGDF/AeMQ6htIZaqc+W6+8fTB5j3kf2t1TP0Q2BJP/Fh8HcVysZMatMaIqDMz6e9mKGv\n0dHUucrMziWC+pYRdt8t7r4tpcD8gKHpV/OJhXWG82kqrx462eqI1LqRptf7NlmnhohMIqVVTAB3\nv5Xo6Xgy0cv0F2CghkO7iX8Q/+DuT6t1WeC0OtNbiKmNfk3llZlKbiO+ij1tIr6KTO16HPGP7M9E\nL9aUHoDi7ncCjyG+Dh3uue4AvgKc4O6/rKVeM3shQwdj3kn0fNbSpm5i4Zj88rWXmtmuDASc0tz9\n00Qg/BFgTQ2H3E18Vf94dx/xm5Q0HddpxHzTlQwSf4dPcPev1NTo3eTu3yEGb36EoXnIlTxMDOar\nGpi5+7eJAO9iIkVkHUPn6B0z7r4FeArRE39rlV0HiFSlJ7j7BbuxrPxYOgt4L3AtO8/SUzRItP9M\nd3+BFv8Q2TOY+3SdfnbPlnqbjky3RWQ9PNuIXt/bgNvTIKvdPVc78c97f2LgRwfxD/FPtQbcUps0\nt/BpRK9xC/E8rwGuSTmhMsnSB4QTiW9y5hABzBZgJfE3N1IwWa3uI4gPpYuJD7drgOvd/cHdbfdu\ntMmI6z0WWEikenSktt0G3OF7+D8CMzuIeF73Id4rNwFrib+rSV8JbzhpBpNjiZSdxcRz308Mmr0X\nuHGS86NFpAIFxyIiIiIiidIqREREREQSBcciIiIiIomCYxERERGRRMGxiIiIiEii4FhEREREJFFw\nLCIiIiKSKDgWEREREUkUHIuIiIiIJAqORUREREQSBcciIiIiIomCYxERERGRRMGxiIiIiEii4FhE\nREREJFFwLCIiIiKSKDgWEREREUkUHIuIiIiIJAqORUREREQSBcciIiIiIomCYxERERGRRMGxiIiI\niEii4FhEREREJFFwLCIiIiKSKDgWEREREUkUHI+CmXm6LZnstoiIiIjI2FNwLCIiIiKSKDgWERER\nEUkUHIuIiIiIJAqORUREREQSBcc5ZlZnZhea2S1m1mVmj5jZT8zs1BqOXWhmHzCzv5pZh5ntMLMV\nZvZ+M5s3wrHHmdllZnafmXWb2RYzu9bMXmtmjRX2X1IaHJgen2Jm3zOzdWY2YGaX7PqzICIiIrL3\napjsBuwpzKwB+B5wVtrUTzw//wA83czOqXLsE4EfA6UguBcYBI5Nt5ea2dPc/a4Kx14AfILsg0oH\nMBN4fLqdY2ZnunvnMOc+B/haautWYKDWaxYRERGRodRznHknERgPAm8H2t19LnAo8BvgskoHmdnB\nwE+IwPizwBFAC9AGHA/8GjgQ+IGZ1ReOPRu4FNgBvANY6O6zgFbg6cA9wHLg41Xa/UUiMD/E3eek\nY9VzLCIiIrILzN0nuw2TzszagHXALOBid7+oUN4M3AgckzYd4u6rUtnXgBcDH3T3f6lQdxPwZ+AE\n4Hnu/r20vR5YCRwMPN3df1Xh2MOAW4Em4CB3X5e2LwHuS7tdC5zm7oO7dvUiIiIiUqKe4/B3RGDc\nQ4VeWnfvAT5S3G5mrcDziN7mj1Wq2N17iXQNgKflipYTgfGKSoFxOnYlcB2RMrF8mLZ/VIGxiIiI\nyNhQznF4TLq/2d23DrPP1RW2LSN6dR34q5kNV39Luj8wt+3x6f4IM3uoStvaKxyb98cqx4qIiIjI\nKCg4DgvT/doq+6ypsG1xujdgnxrO01rh2OZdODbvkRqOFREREZEaKDjePaW0lK1pMNyuHPtjdz97\nVxvg7pqdQkRERGSMKOc4lHpf96uyT6Wyh9P9bDNrr1BeTenYg0Z5nIiIiIiMEwXH4cZ0/ygzmz3M\nPqdX2PYXYj5kI6ZeG41SrvAJZrb/KI8VERERkXGg4Dj8GthG5P++sViYpmN7a3G7u28Hvp8e/ruZ\nzRruBGbWYGYzc5uuAB4E6oEPV2ucmc0d6QJEREREZPcpOAbcfQfwofTwvWb2FjNrgfKcwj9k+Nki\n3gVsAo4E/mBmTy8t+WzhaDN7O3AX8NjcOfuAC4iZLl5oZj8ys0eVys2sKS0L/VGyOY1FREREZBxp\nEZBkmOWjO4A56edzyHqJy4uApGNPAn5ElpfcR/REzyKmeitZ7u5DpoQzs/OAz+X260q3dqJXGQB3\nt9wxS0gBc367iIiIiOwe9Rwn7t4P/BPwBmJVun5gAPgZcLq7/6DKsX8GjiaWoP4DWVDdSeQlfzLV\nsdNcye7+ZeAoYsnn29I5ZwMbgauA96ZyERERERln6jkWEREREUnUcywiIiIikig4FhERERFJFByL\niIiIiCQKjkVEREREEgXHIiIiIiKJgmMRERERkUTBsYiIiIhIouBYRERERCRRcCwiIiIikjRMdgNE\nRKYjM7uPWAp+1SQ3RURkKloCbHP3Qyb6xNM2OF64z2wHOOjgfcrbOju6AJjV0gzA2rVbymWPWrIv\nABee9UwA/nDjXeWyr/7mjwBsG+gD4ORHZ7+nnsFuAO66Zz0AmzZ2lcsGiKW5H3vUgQC8+OxnlMu+\n8sNfA3DznSvL21pnzgbg8AMXR/seWVcuO+KwOQAsmh33LTazXPYgJ8a5+44FoL83+7WuW/n1aEvX\nJgAaGmaVyzp2rAagq+NvhoiMtdktLS3zli5dOm+yGyIiMtXccccddHV1jbzjOJi2wXFdCve2bNle\n3jYYsS0NXh/3DfXlMk8JJht3dALQ2tZWLmtujsLmtH9vU0+5rFRXc3NTPG4cyOocjODY6uL4HVt6\ny2Ub1m5L7fTytr7+qLexPuqc0dRSLtu2rR+AmfWD0QbbkV1XW9TR2hofBHq8sVw2a+4pAHS3PhR1\nenZddfXZzyJ7CjNbBeDuSya3Jbtt1dKlS+fdcMMNk90OEZEpZ9myZdx4442rJuPcyjkWEREREUmm\nbc+xiMhkW7FmK0ve9bPJboaITAGrPnjmZDdBkmkbHNfVx6VtzaVV9Keshv6WSH1oaMg6zvtTfvDv\nb7kFgEFrKpe1L45c4AXtsW1Oe5a2sPmRSG/wdPzMWe3lskGL9IhZ7QsBeHjjxnJZR1dHtKE+9yuw\naFe9RUPb22ZkRXVRf1dPXE97e5ZyYQ2RO907EG3p7c2Oa5/zWABaiPMN7ujIHae0ChEREZE8pVWI\nyISzcIGZ3WZm3Wa2xsw+ZWbtVY55oZldaWZb0jF3mNm/mlnzMPsfbWaXm9mDZtZrZg+b2TfM7KgK\n+15uZm5mh5rZhWZ2q5l1mdlVY3jZIiIyBUzbnuOZaUBdY9Ps8rb1D28GYEdXzDAxc2bWO9zjMRju\nxnvuBWCgMZvAoX5W1OV90TM707I6+9N56utjROVgrg1ts2K/OfP2A2BrXzb4rr85enebc//XFy6M\nGSjmtMavpbEha8P23mhzXfo8M6M1m62CgRis19cXPc7bt28uF82bdWi0pXX/aF9T1nvdb1mvusgE\nuwR4A7AO+DzQB5wFPA5oAnrzO5vZZcB5wGrg+8AW4BTgfcBTzOxp7t6f2//pwA+ARuAnwL3AAcBz\ngDPN7Ax3v7FCuz4BPAn4GfBzYKDCPiIiMo1N2+BYRPZMZvZ4IjBeCZzs7pvS9vcAVwKLgftz+59L\nBMY/BF7s7l25souA9wKvJwJbzGwu8E2gEzjN3W/P7X8ccB3wReAxFZr3GODR7n7fKK5nuOkojq61\nDhER2XML/FX8AAAgAElEQVRM2+C4qzv+f+6zeP/ytoGB6Lld+2DMSTyjJcu5nTW3FYDmlsjl3dGX\n5ebOWxQ9wL3bIrd3zswsp/eRjdGbnDpvaWjM8pHnLZwPQEtrzE28rSd7ugdaD4vz9a0tb1u8IKZi\nO+7wA6Kdj2wol92y8m8AtM6MutavzaZyW9sV07S17hc94fX1W8tl3V3RE946I+Y3tsas17ttzrT9\n9cue7bx0//5SYAzg7t1m9i9EgJz3RqAfeEU+ME7eB1wAvJgUHAMvA+YAF+QD43SOFWb2BeBNZnZM\nsRz40GgCYxERmX4UHYnIRCv12F5doez35FIZzKwVOBHYQAS0lerrAZbmHp+a7k9MPctFR6b7pUAx\nOL6+WsMrcfdllbanHuVKvdMiIrIHU3AsIhOtNOju4WKBu/eb2YbcprmAAQuJ9IlazE/3rxphv5kV\ntj1U4zlERGSamrbB8Y40ZdlDD2VpC709MVyuviEuu6UlG5C3vTNWrGueEWkHhyzer1w24LG0Xldr\nSpnITQHX0RUr6m3aFCkX++x3cLnskEMPSHVG+sam3qzOtkWRxjHw8C/K29Y8ELHCXb1xvsUHZPs3\np6nlmtNAwTWPZKkT2zsjXaR+3iMA9PdlA/I6tkbHWCmdonn2ceWywb7JWZZR9nqlF+8+wN/yBWbW\nACwgBt7l973J3WvthS0dc6K73zrKtvnIu4iIyHQ2bYNjEdlj3UikG5xOITgGngiU13V39w4zuw04\n1szm5XOUq7gO+Cdi1onRBsdj6rj927lBE/uLiEwp0zY4XrBgHgAdHdnAui2bY7q21jT92o6ubLao\nptT7WlcXg+22bsoGvG3YFD2yVh+9tq112aC7+YtjgNycB2L/Wc3d5bKODWsA2DYQ2waaDiiX7bPk\njCjz8qB86ntWAbC6I9rVuCXrAT7hkAMBGLSoq3Mw1+vbH73K2zf+BYCu3EIfXRuj57ihORYiWdS2\nb7lsx+asV11kAl0OvBJ4j5n9ODdbxQzgAxX2/xjwJeAyMzvX3bfkC9PsFIfkpmb7MvAe4L1m9md3\nv76wfx0xi8VVY3hNIiIyTUzb4FhE9kzufq2ZXQpcCKwws++RzXO8mZj7OL//ZWa2DDgfWGlmvwIe\nAOYBhwCnEQHxa9P+G83sucTUb9eZ2RXAbUTKxIHEgL35wAxEREQKFByLyGR4I3A3MT/xa4CNRDD7\nbuCW4s7u/noz+wURAD+VmKptExEkfxj4WmH/K8zsBOBtwN8TKRa9wFrgt8RCIiIiIjuZtsFxX2/M\nBuWeTf3U3h6D0+vqUwpFQ7aeXWtbGiCXJix+ZHNulbk5MZitvSXmCp6bW3V76/r4hre5LQbgt807\nolw2qz62LZwV+9+9cWW5rK419ps7M5uHuWV2pEM01Q+kNjxYLjt6yYkA3LcmDaa3bOGuOQuifT0W\n7euzbExRU1qArzelbHRt+1O5zAYeQWQyuLsDn0q3oiXDHPNT4KejOMcqYg7kWvY9Fzi31rpFRGT6\nqht5FxERERGRvcO07TnesiUGyM2dO6u8bd6C6B0u9brOnNlcLmtPq8Vt3RwD3uqbs6dmn4XRAzy7\nPlbPa+/NembX98fA+u7B2LaxL+sJ3qc+BgWecET0UG/clvUcP/TIbwBoGcgNiqtPq+0Nxv4zWlvL\nRTfcFgPretNKfIcfeFS57IGeGBTYuyOutbWlv1xWmr7OiPvubQ+Uy7q7ahn4LyIiIrL3UM+xiIiI\niEgybXuO+2MdDQYHc/m3aWx6W2v8MGNGtghIf39MjdbZFT3HzY3ZdG09PbHQR//MeLoGWrKnzVuj\nji3bY1GvvrZsGrWNC08H4IY10VvbPKOvXDbHbgCgtz437VpX9PjutyimW6sbzPKlV95zBwBHHx25\nyocuObVctubuyB3uG1wFgPWuKZf19Uf9jTP2ifvGRdk1D25DRERERDLqORYRERERSRQci4iIiIgk\n0zetoj9SFDZv3lreNnN2pFjMapsLQF1dlrZQZ5FGUV8f900NWcrFYBrMti2tSuctM8tlGy32608D\n31psv3LZQPsTAVix4x4AZm+9uVx27H6RvrGmO0u1aPCYkm2f9hjIt/Leu8tlRx11JABz5sTgu20d\nndnFegzkq2c1AN3bsyng2poXA9A6J9IxBjwbrNfSuAARERERyajnWEREREQkmbY9x556e3t7s4U+\ntm2JXto5s3sB6OnuKZfNS9O19falAWy5hTQGPX4esKhre1/Wa9vZH73PTR69vbMas6njvD6mefO2\n6KHtfmR+uax9RtQxf9Fh5W0z58R+d99+LwBHHpaVtaWBf3fddR8AD3VlK+yueWToYh59/dk1L97/\n5GhDe9Q90H1XuazJ+xARERGRjHqORURERESSadtz3JqmayvdAwykXt7G+sgZ7uzM8pG3bu1KP8Xn\nhfqmbIGQpobIQ+7ZHvsM1mX5yL2bond4/tx4Kg84NMv3HRyMnx9eH0s2e3+WQ7xjR6q7K5tObfWq\nyBleuTKOO/mxjymXzZ/VFq1LC5h09GfHDXZtB6CrO3q4Z8ybXS6btSB6nzsGo32Nddmy2NapRUBE\nRERE8tRzLCIiIiKSKDgWEREREUmmbVpFQ30LAH19A+VtPhgD0Navj3SCGc1ZesS6B2PbzNmRTrF9\n+5ZyWf2CWF2uqTfSK1av214us/4YgLf4gEjfGBh4oFzWtf5nAHSvux6Ag+ZlqRBGKwCd9dngue7u\nyLVYsjgGzy3Zf065bN/99gfguhWRmmGeXZc1RbpHXW9MD7fP7CwlZEZL1Llja0s6ycPlsua6XkRE\nREQko55jERkzZrbEzNzMLp/stoiIiOyKadtz3NMTU6UNDGbTle23f0y31jYrPhMM9mdTuc2eGQPe\n2tqiR7e3v6tc1toWPcyz5sV0b+s2Z1O5LVmSepp7owd545bs80bP9j8CcPKyAwE44/gnlcvuuSl6\nkw879qjytuOOjoU+7rsrBuStvD/rhb7i2lsBWLttXwCssbFcVpd6jmfNimud3ZL1HPf3RY94X7rU\nwY6s53hG27T99YuIiIjsEkVHIiLjZMWarSx5188m5FyrPnjmhJxHRGS6U1qFiIiIiEgybXuOS+kU\ng4PZwLX+/tg2N6VHNDZauaxjewxO27olUhTmLsjmRyYNmtvaHfMi17Vkg+gaWqIOHzw0yuqyOYaP\nOSLquuD8lwKw9JCF5bI/7R+r5fV0dJS3LZgfg+buTW3+yy0ry2V3PRyDAOvnxYp3cxfOK5f19MUg\nvb6tsVLe9h1Z2odvXB9labCe5+ZH7ujMrkNkrJnZEuCDwFOBmcAK4CJ3/2lhv2bgzcCLgcOAfuAW\n4FJ3/06FOu8D/gf4T+B9wBnAAuDJ7n6VmR0KvAt4MrA/0AWsAa4F3uPuGwt1vhB4NfBoYEaq/+vA\nh929BxER2atM2+BYRCbVwcD1wN+ArwLzgHOAH5vZU939SgAzawJ+BZwO3Al8GmgFngt828we5e7v\nrlD/YcCfgLuJQLYF2GZmi4E/A7OBnwPfJwLeQ4CXAp8CysGxmV0GnAesTvtuAU4hgu6nmNnT3L2/\n2oWa2Q3DFB1d7TgREdkzTdvguK4uXZpnvcPdXdEju/7h6Fmdt6C1XNbbH///1q6Lntb+wawHeH4a\nwGdpdbq+gaw3evum6FiaMz8GytGXZaosao399psbg/WaZ2a90cvOeCIAgx07svZtiBXyWppjBb/W\nWe3lstmDUW9/w9q4vsGs86tuIHqFe/vimrt6smuuS73d3V1pqrqGXNu3Zb3IImNsOdFLfHFpg5l9\nA/gl8HbgyrT5rURg/AvgWaVA1MwuJoLrfzGzn7r7Hwr1PxH4QDFwNrMLiUD8Te7+iUJZGzCYe3wu\nERj/EHixu3flyi4C3gu8HhhSj4iITG/KORaR8XA/8B/5De7+K+AB4OTc5lcADrwl30Pr7uuJ3luA\nV1ao/2Hg4grbS7qKG9x9Rz4ABt5IpHC8orCddO6NRKpHVe6+rNKN6AkXEZEpZtr2HA/0RweRe35r\nXO5D6+L/4EMPZQt97Ls4FtyY3R49xi0z2splvb2lntiobFZb1qs8uyX2a2mJfN+OTevLZffeFjnD\n1199CACnnbm8XNbSlqZis2whkrpt0cP86GOOB2D1xq3lstXX/A6Arg0xvVtvU+5X1xsxxSBpCreG\nrO2NddFTXDcQ7Wtsyj4PdQ7os5GMm5vdcyvVZB4ETgUws1nA4cAad68USP423T+6Qtktw+QD/y+R\ni/xpM/t7ImXjWuB29+zdwMxagROBDcCbzKxCVfQASysViIjI9DVtg2MRmVRbhtneT/aNVSlvaN0w\n+5a2z6lQ9lClA9z9fjM7GbgIeDrwnFT0oJl9xN0/mR7PBQxYSKRPiIiIAEqrEJHJU/pqZN9hyhcX\n9svzCtuiwP0Odz8HmA88lpi5og74hJn9c6HOm9zdqt1GdUUiIjLlTdue45bWuLS+vmygeWdXTIfW\n0xX/Vwdy07z19cXPhx95AAD77jO3XFaX0hd7u+Nb3M2bN5XLZh8Ug/q2b4rp1Ho7soFyjWnquDWr\nVwGwZe3actmMhZGa0b0123/tvbEynnfFZ5ajD16QnecPkYZx/yMx9Vtde5aOMdAT7WpsjGtobsnS\nKuqIbda/GYD+XEwxo6kFkcni7tvNbCVwqJkd4e73FHY5I93fuIv19wM3ADeY2R+A3wFnA19y9w4z\nuw041szmufumanXtquP2b+cGLc4hIjKlqOdYRCbTZUR6w4fNrL600cwWAP+W26cmZrbMzNorFO2T\n7jtz2z4GNAGXmdlOqRtmNtfMHlPruUVEZHqYtj3H+x8Yi2R0d/eWt9XXxTekW7bG9Gk7tmdlfX3R\no7ptW5S1zcy+TZ3VHGUL5kZvcn9PX7msuz96cnt7o/fWB7KyAYue2YYZ0bu88YGs53hwTQysG+zc\nXN529x33psbEuectPqBcduzBscjIyvsjDbOzf0O5rKEhfo1ts2MKuLZ5WWzQsTXa1dcb7ezqzX7l\npm+MZfJ9BHgGcBZwi5n9nJjn+HnAIuBD7v77UdT3UuA1ZvZ7YCWwmZgT+R+JAXaXlHZ098vMbBlw\nPrDSzEqzacwj5kU+Dfgy8NrdukIREZlSpm1wLCJ7PnfvNbOnAW8BXgRcSLZC3pvc/ZujrPKbQDPw\neGAZsTjIGuBbwEfdfUXh/K83s18QAfBTicF/m4gg+cPA13bx0kREZIqatsFxX1/0mHZsz2Z7mj8/\nvjndf//IyR3IrXv1yProwe3tiSngenqywhkpTbeH6FU+cHE2fmhjZyyk0dUTecmzZmfTvHlaEOTH\nv7kJgDvvztIaj0orSc+tz3qvZ7VFz2/PYLR5y4Zs/6P3i7YPnnQcAKvWPVAuuzv1SHuamm3Lw6vL\nZVu3RPvqUy+x5XKOu3u0Mq6MLXdfRaRJDFe+vMK2bmL6tf8cg/r/RKycV7O0nPVPR9xRRET2Cso5\nFhERERFJFByLiIiIiCTTNq2itzemMNuWBt8B9KTBeU0z4lvZGc0zymVd3bHfYJrebdumLK3i2OOP\nBOCgRZELsWp1ltIw0BdpGB0dcXxDXWO5bL99YoD87ffFea68IUuTuImYtu3Eg7M2PO8ZT4k2pHau\nX/9Iuay9OVa/O+XIgwE4bkmW2nFt660ArNscA/E7OrNUjXmzoj1zZs9P1zdYLrvrgTWIiIiISEY9\nxyIiIiIiybTtOe7rjR7SBQvml7e1tMbCGa1t0Zu6JQ1WA5iVpkGrs+hVbsh9bqhL43+WHBLTqa15\nOJtGrT/1GBvRA/zgg9mqtjNSD/XMeYcAUN+U9fZu39ANwB1rsl7o7T3Raz27Ln4tNpAtUkJaUGTB\nrBhMOHcwG5P0lEcvBaDUYWy53uu6upg61tI4vP5cnT/5w18QERERkYx6jkVEREREEgXHIiIiIiLJ\ntE2rKM1TvHBhtipsZ1cMWGtqjpSEUsoBwOxZKa2iPvIP2pqyzw3b0+p3f7z5ZgBWrs5SJzZuj7SK\nnr5I2ejuztrQ3x9tWJCyKXpb28plWwZisN6Dq/5a3nbHykixOP6AxXF8b24Fv96o2NviPDMasrSK\nea0xWG+/uXENLS3ZIL+6+rjG0mDEwdwUsaeecBQiIiIiklHPsYiIiIhIMm17jru7Y8W6zZuzwXO9\nvf3pPgasdXZkK8T1dEfZ4v3mxYZcz+wj27cDcN+6dfF4fUe5rGNbHNefVqebPTvrtW1qbIl7i57m\nhqasrDGNE3zgrr7ytmv+dCMAcxseC4B3bs8uKA0U7B+MA1tzdTUPRG+3pWno6simofPB+LmhMdpX\nZ9mvfOnBByAiIiIiGfUci4iIiIgk07bneOGi2QC0tLSUt3V1Ri9taR2MTrIFMTo7I6d38+bNAMxv\nn1kuq7f4DNE+L3qVN2zMemYbm6KO1pTH3N7eXC7r6IgcZyx6nJ2ucpkNRu91Q1OW9/zXu/4GwLEH\nLQLg0AVZG0ht7R8o9X5n+cgNpSq8tE92XX3p50Fip9aW1nLZgln6bCQiIiKSp+hIRERERCRRcCwi\nIiIikkzbtIrZ7TFgzXMryc2dF6kWD96/HoD+Xi+Xtc1qTtsibcH7coPa0mC2Hdti2rYdWzvLZQ0N\nzUPON3N2liYxkFajG+iN49dvur9c1tMTgwG378jq6uuKbes2xCDCA+dlg+5KKRPdaTq6RrK0itYZ\nkaJRutLuLHsD6qJ9bmlKt55shTzLDdwT2duZ2VXA6e5uI+0rIiLT17QNjkVEJtuKNVtZ8q6fjUvd\nqz545rjUKyKyt5u+wbFHr3BvTzZdW31a9KMuDW4b6Mt6UWfPjF7aGS2pzLLOox3dqQc49d7OaM16\ndNev2wRAd3f0Ks+Zm5UtWtgOgKWBb30D2fm2bI8BgN19Wfs8DbbbuDWmcOvpzfZvbYpfVWfaNqMp\n+9VZQ+ol74s6+wazAXkNjbFfafGPrr6sx7nOs/pFRERERDnHIjIFmdnJZvZtM1tjZj1mts7Mfm1m\nz8/tc66Zfd/M/mZmXWa2zcyuNbOXFOpaYmYOnJ4ee+521cRemYiITLZp23PcmHKBe8jyivvS9Gcz\nZsQSzDvqs15UH4yffSDyd9dv2VIumzs/plSbM6c91d1ULtuxLXp5438rDA5k5ystOrJla9SVX666\nzhpTW7Je3u1pOrkNW6IXurMvK2tOec8dXdHO2W1ZD/WAp884aXfPXXOpZ9rSuftz7av3rH6RqcLM\nXgV8FhgA/he4B1gEPBY4H/hO2vWzwG3A74B1wHzgmcBXzewod/+3tN8W4GLgXODg9HPJqnG8FBER\n2QNN2+BYRKYfMzsG+AywDXiSu99WKM8v+3icu68slDcBvwDeZWafc/c17r4FuMjMlgMHu/tFo2zT\nDcMUHT2aekREZM+gtAoRmUpeR3yof18xMAZw99W5n1dWKO8FPp3qeMo4tlNERKaoadtzvKMjUhQa\nGhrL2wYHI82htTVWzeuelaVV9PTG/gP98XlhICuilAzR39cBQGNDlppw6OGLAehLx/f2ZgPsGpsi\n/aJzR2zry61cN5AGxuVTIAbSDFKrH4lV+lauXl8uO3y/hencscrforlt5bLNW7cBYH0xzVtd86xy\nWZ+XzmND7gEa6rJzi0wRp6T7X4y0o5kdBLyTCIIPAloKu+w/Fg1y92XDnP8G4DFjcQ4REZk40zY4\nFpFpaU66X1NtJzM7FLgemAtcA/wa2ErkKS8BXg40D3e8iIjsvaZtcLx1a/Tytra2lrc1lac/ix7T\nmbOyjiT36JHdujl6X5sas8Fzc9pjIF7rzOh13bYtG6zX0Bh1HXTQvgCsXfNQuayzO3qMfTB6owf7\ns6nTSlOxDfT0ZY2ui/o3bo9VPO5bt7FctO+8iAnqSdO15aaF27ptKwCNaVDhzPbsf35dc/ScD6SB\nePm+YqvTWgcy5ZT++PYH7qyy31uIAXjnufvl+QIzeyERHIuIiOxk2gbHIjItXUfMSvEMqgfHh6f7\n71coO32YYwYAzKzefWwmAT9u/3Zu0GIdIiJTigbkichU8lmgH/i3NHPFELnZKlal++WF8r8HXjlM\n3aWvag7a7VaKiMiUNW17jru7S3MaZ/MBDw6mzqCUW7B48aLsAIvBej1dkRbRk0t32JHmH25oinSF\nxqYsVaOzO6VhpEyGRYvay2V/vX0tAP098Rlk/txsoFxzeuZ7u7NBek1pNbvOvjQ/clfWhp6UFtGf\nzrd9R2fWvo74udli//oZ2aDAGY2ROlI6S09PbqQhjYhMJe5+u5mdD3wOuMnMfkzMczwfOImY4u0M\nYrq384Dvmtn3gLXAccDTiXmQz6lQ/RXA84AfmNnPgS7gfnf/6vhelYiI7EmmbXAsItOTu3/BzFYA\nbyN6hs8GNgC3Al9M+9xqZmcA/wGcSbzX3QI8h8hbrhQcf5FYBOQFwDvSMVcDuxocL7njjjtYtqzi\nZBYiIlLFHXfcATGAesKZu6bzEhEZa2bWQ8wEectkt0VkGKWFaqrl74tMlhOBAXef8JmF1HMsIjI+\nVsDw8yCLTLbS6o56jcqeqMrqo+NOA/JERERERBIFxyIiIiIiiYJjEREREZFEwbGIiIiISKLgWERE\nREQk0VRuIiIiIiKJeo5FRERERBIFxyIiIiIiiYJjEREREZFEwbGIiIiISKLgWEREREQkUXAsIiIi\nIpIoOBYRERERSRQci4iIiIgkCo5FRGpgZgeY2WVmttbMesxslZldYmZzJ6MekaKxeG2lY3yY20Pj\n2X6Z3szsuWZ2qZldY2bb0mvqa7tY17i+j2qFPBGREZjZYcAfgEXAj4E7gZOBM4C7gCe4+8aJqkek\naAxfo6uAOcAlFYo73P0jY9Vm2buY2c3AiUAHsBo4Gvi6u79klPWM+/tow+4cLCKyl/gM8Ub8Bne/\ntLTRzD4GvBl4P/DaCaxHpGgsX1tb3P2iMW+h7O3eTATF9wKnA1fuYj3j/j6qnmMRkSpSL8W9wCrg\nMHcfzJXNAtYBBixy9x3jXY9I0Vi+tlLPMe6+ZJyaK4KZLSeC41H1HE/U+6hyjkVEqjsj3f86/0YM\n4O7bgWuBVuCUCapHpGisX1vNZvYSM3u3mb3RzM4ws/oxbK/IrpqQ91EFxyIi1R2V7u8epvyedH/k\nBNUjUjTWr619ga8SX09fAvwWuMfMTt/lFoqMjQl5H1VwLCJSXXu63zpMeWn7nAmqR6RoLF9bXwae\nQgTIbcDxwH8DS4BfmNmJu95Mkd02Ie+jGpAnIiIiALj7xYVNK4DXmlkH8FbgIuDZE90ukYmknmMR\nkepKPRHtw5SXtm+ZoHpEiibitfW5dH/abtQhsrsm5H1UwbGISHV3pfvhctiOSPfD5cCNdT0iRRPx\n2nok3bftRh0iu2tC3kcVHIuIVFeai/PvzGzIe2aaOugJQCdw3QTVI1I0Ea+t0uj/v+1GHSK7a0Le\nRxUci4hU4e4rgV8TA5JeXyi+mOhJ+2ppTk0zazSzo9N8nLtcj0itxuo1amZLzWynnmEzWwJ8Kj3c\npeV+RUZjst9HtQiIiMgIKixXegfwOGLOzbuBx5eWK02BxH3A/cWFFEZTj8hojMVr1MwuIgbd/Q64\nH9gOHAacCcwAfg482917J+CSZJoxs7OBs9PDfYG/J76JuCZt2+Dub0v7LmES30cVHIuI1MDMDgT+\nHXg6MJ9YiemHwMXuvjm33xKGeVMfTT0io7W7r9E0j/FrgUeTTeW2BbiZmPf4q66gQXZR+vD13iq7\nlF+Pk/0+quBYRERERCRRzrGIiIiISKLgWEREREQk2auCYzPzdFsyCedens69aqLPLSIiIiK12auC\nYxERERGRahomuwETrLSySt+ktkJERERE9kh7VXDs7kdPdhtEREREZM+ltAoRERERkWRKBsdmtsDM\nzjezH5vZnWa23cx2mNntZvYxM9tvmOMqDsgzs4vS9svNrM7MLjCz681sS9r+qLTf5enxRWY2w8wu\nTufvMrP1ZvZNMztyF65nlpmda2bfMbMV6bxdZnavmX3ezI6ocmz5mszsIDP7gpmtNrMeM7vPzD5i\nZrNHOP9xZnZZ2r87nf9aM3utmTWO9npEREREpqqpmlbxLmKJS4B+YBvQDixNt5eY2VPd/dZR1mvA\nD4CzgAFi6cxKmoErgVOAXqAbWAi8AHiWmT3D3X83ivO+HLg0/TwAbCU+uByWbi8ys7Pd/TdV6jgR\nuAyYl9pdR6w9/lbgdDN7vLvvlGttZhcAnyD7oNQBzAQen27nmNmZ7t45iusRERERmZKmZM8x8ADw\nbuAEoMXd5xMB62OBXxGB6jfMzEZZ73OIpQjPB2a7+1xgH2Lt77zXpXO/DJjp7u3Ecps3Aq3Ad8xs\n7ijOuwF4P3Ay0JquZwYR6H+dWMLzG2bWVqWOy4klPo9399lEgPvPQA/xvLyqeEBa5/xSYAfwDmCh\nu89K1/B04B5gOfDxUVyLiIiIyJQ17ZaPNrNmIkg9Blju7lfnykoXe4i7r8ptv4hsve/XuPvnh6n7\ncqKXF+Al7v71QvkC4E5ine9/c/f/yJUtJ3qbK64TXuV6DPg18FTgXHf/n0J56ZpuA5a5e0+h/FLg\nAuBKd39ybns9sBI4GHi6u/+qwrkPA24FmoCD3H1dre0WERERmYqmas/xsFJw+H/p4RNGefhGIjVh\nJPcD36hw7g3Af6eHzx3luSvy+PTys/Sw2vV8rBgYJz9K98cVti8nAuMVlQLjdO6VwHVE+s3yGpss\nIiIiMmVN1ZxjzOxookf0NCK3diaRM5xXcWBeFX9x9/4a9rvah+9yv5pI+TjOzJrcvbeWE5vZAcCF\nRA/xYcAsdv7wUu16/jzM9jXpvpjm8fh0f4SZPVSl3vZ0f2CVfURERESmhSkZHJvZC4CvAKWZFAaJ\nQWylntOZRJ5utRzdSh6pcb81NZTVEwHpwyNVZmanAz8l2l2ylRjoB9ACzKb69Qw3eLBUR/F3vTjd\nN0JXMgAAACAASURBVBN51SNprWEfERERkSltyqVVmNlC4AtEYPxtYrDZDHef6+77uvu+ZAPIRjsg\nb2DsWlqbNFXa14jA+DdET3iLu8/JXc9bSruP4alLv/sfu7vVcLtoDM8tIiIiskeaij3HzyACyduB\nF7n7YIV9aukJ3R3V0htKZQPA5hrqOhU4ANgEnDXMlGnjcT2lHu2DxqFuERERkSlpyvUcE4EkwK2V\nAuM0u8OTi9vH2Ok1lK2oMd+4dD13V5lL+Kk1t6x2f0z3J5jZ/uNQv4iIiMiUMxWD463p/rhh5jF+\nFTGgbTwtMbMXFjea2Tzg1enhd2usq3Q9R5jZjAp1/h1wxi61srorgAeJ3OgPV9txlHM2i4iIiExZ\nUzE4/g3gxNRknzSzOQBmNtvM3g58mpiSbTxtBb5gZi82s4Z0/hPIFiBZD3ymxrquBTqJuZG/YmaL\nU30tZvYK4PuMw/Wk1fIuIJ7LF5rZj0rLZKfzN5nZKWb2UeC+sT6/iIiIyJ5oygXH7n4XcEl6eAGw\n2cw2E/m9HyJ6RD83zs34LLCCGEjXYWZbgVuIwYGdwPPcvZZ8Y9x9C/Av6eHzgLVmtoVYEvtLwL3A\nxWPb/PK5/5dYRa+XWDL7JjPrNLONxHX8kRgM2D58LSIiIiLTx5QLjgHc/S1E+sJNxPRt9ennNwFn\nArXMVbw7eohFMf6dWBCkiZgG7lvAY9z9d6OpzN0/SSxdXepFbiBW2nsvMR/xcNO07TZ3/zJwFPGB\n4zZiIOFsorf6qtSGo8br/CIiIiJ7kmm3fPR4yi0ffbGmNhMRERGZfqZkz7GIiIiIyHhQcCwiIiIi\nkig4FhERERFJFByLiIiIiCQakCciIiIikqjnWEREREQkUXAsIiIiIpIoOBYRERERSRQci4iIiIgk\nDZPdABGR6cjM7iOWYl81yU0REZmKlgDb3P2QiT7xtA2OL7l8RZqGI5uNo66+PrbUWTyuyzrOSz/X\nEWX16R6g9GNd6bj6/JmGzvZhZjv9XJoRZKSZQbL90uPBumHLGOzPDkw/Dw4ODrnPHzcwMJjuB7LD\nBuPnt732lNzFisgYmd3S0jJv6dKl8ya7ISIiU80dd9xBV1fXpJx72gbHpYDW2DnusyqhoO30Qxbk\nZoHvzkGuVau05n1K9ZYaX2n/nc9d3JI/LIvHfaeyGposIrtu1dKlS+fdcMMNk90OEZEpZ9myZdx4\n442rJuPcyjkWkSnBzK4ys1FNzG5mbmZXjVOTRERkGlJwLCIiIiKSTNu0iroKOQPltAarG/o493Nd\nKquv2/lzQynn2CzL6WWnlIud1ZJyAeBeylFOj9k557icT1yXz50YmkOdSzkGBoa0odI1i0xjS4HO\nyTr5ijVbWfKun03W6UXG3KoPnjnZTRAZd9M2OBYRcfc7J7sNIiIytUzbtAqzunSz8q2uLm7Z47qd\nbla62c77leussF+lunb1VqnOcnvK581uO+1T463O6so95SKTycyeZWZXmNk6M+sxs7VmdrWZnV9h\n3wYze7eZ3ZP2fdDM/svMmirsu1POsZldlLYvN7OXm9lNZtZlZuvN7DIz23ccL1VERPZw6jkWkUll\nZq8G/ht4CPgJsAFYBJwAnAd8pnDIN4AnAb8AtgHPBN6RjjlvFKd+M/B3wLeBXwJPTMcvN7P/z96d\nh9lVlfke/741D0kqqQwEEkgCMikYIIqKKEFaUGnb4Wq3thPa3Yra7dB2X3HoB9B2vF7liq04041z\nazuDogjIIK0NMs9DEAIhY6VSqbnOe/9419l718mpSlVSSSWnfh+e8+yqtfZee52qw8k6b71rrWe4\n+4YJ9n+s5SiOmkRfRERkH1Gzg+Msx3ZUWVrLuEr+bbmsnMpbTDmuSFWuyNXdcc3kiRhvzeM8nTg/\nJ+tDeb3jUSnHo59PtbziLKe60M9Rqcki0+ctwCCw0t3XFyvMbEGV8w8DnuLum9M5HwBuAV5vZu9z\n93UTvO8LgWe4+x8L9/sM8C7g48DfTPqZiIjIfk9/UxeRfcEwMFRZ6O4bq5z73vLAOJ2zHfgm8X72\ntEnc85LiwDg5D9gK/LWZNU+kEXdfVe0BKN9ZRGQ/pMGxiEy3bwJtwJ1m9hkze6mZLRzn/P+pUvZI\nOs6bxH2vrixw963AzUALsdKFiIjMMDWfVjGqLB3LW0TXFZIuyl9newwU9hqw8tbS2VJuO36mqJbS\nUGln20fnjcV5dYXzS1kSRByLaRWlSaRVjO7zxLojsie5+6fNbCPwNuAdRFqDm9nVwD+7+/9UnN9V\npZnyfur1VerG8sQY5eW0jI5JtCUiIjVCkWMRmXbu/h/u/kxgPnAm8FXgucAvdxJF3h0HjFFeXq1i\n6x66r4iI7MNqNnKcTzzzHcoqj1CYpFdXnri2Y1vVJt1NJGJceS5UjyKXy8o1431yKRV2+hhvMmDl\nfUZGRnbaT5HpkqLClwKXWvyJ5k3EIPkHe+B2pwD/USwwsw7gOKAfuGt3b3DMkg5u1KYJIiL7FUWO\nRWRamdmpVv3T5aJ03FM73L3OzI6vKDuPSKf4trsP7KH7iojIPqxmI8cist/4IdBjZjcAa4jpAc8B\nng7cCPx6D933MuA6M/se8DixzvHJqQ/n7KF7iojIPq5mB8d12WLBhUl3FekRo4JVFesiV41jpRQF\nK6QxVKZVjLqs3IiXD77DdVXTK8qtjOreOOsVpxSLaike5fPK96k2WU9kmp0DnAGcQGzo0Q88DLwX\n+IK777DE2xT5DDEwfxfwV0APcDHw/sr1lkVEZOao2cGxiOwf3P0i4KIJnLd6nLqLiYFtZfm4nwDH\nuk5ERGauGh4cl/9N3DFaW+378vJsVleOsO7YUhZdtmLkeHRb1SKzWXR4VJC4fH5eUo4Al4PCdaXC\nUm47tD/286pmvP6JiIiISNCEPBERERGRpHYjx1na7tjR0WLgtJyjXE5VHpVXXHlO4SOFMTp/ua6Y\n75uuLMd4vbCxiNvwDmXlM0sp0lzHqBtFXTmHeNSSbMOMNsHNRkRERERkFEWORWRGcffz3N3c/arp\n7ouIiOx7NDgWEREREUlqNq2irspks2zyXF3aXW7HldyyTwtemHTnVg/kP6xh8pWl6ixK69P5dRR2\nrsvaSEfP2xxm9BJrozpUVz/6e6C+tBmAkVJqoz7/1ZUzM/JJhYX+ZU+i/Fzyu40/j19ERERk5lHk\nWEREREQkqdnI8XiyoHJxglwKrdZ7RH6LEd1y5Ni9CYChukJEt7689FtEa4esMasrWQsADSnS3Gj5\nJLqmkda4rjCxztIuuUPDG+M4cH9W19hzV1y3Per6ZuW73g7MOjH1If06vRBVzibrlftZWAIOERER\nESlS5FhEREREJKndyHGV7Zwr05CLy7yVl2IbtKZy5Q4XeqprKkSHG+p64piiwg2FRN6Gke3xxeBW\nAIb7Nmd1pZ67ARja/kBWNrjtTwD0bYnj0Ka1Wd0stgHQ1hSfZ0orCv2bsyqOI/HrNM/751kOdPmo\neLGIiIjIWBQ5FhERERFJNDgWEREREUlqNq1i3KXcsmOVtIq6mETX2JAvh9beECkN5TSJtv7tWd3I\n4GMADPRG2dZNa7K63q7bAejesgWAzRs3ZnXNI/0AzG4cyMpa6uI+zc2RFjFUvzyrG+yMrxsPeXL0\nt/PJed8rvrK6wmTCkdHPr/ic6+r02UhERESkSKMjERnFzK4ysz2+B7mZLTczN7OL9/S9REREJqpm\nI8fjG3tSWqvF0mcj62/NyrauuxqAwe7HARje/FhWN9SfIsfbBgFY15VHgh8biOhwx4LDATjk0FVZ\n3fy5MaOurWV2fu+WiBi3zJkLwPpSa1Y3Ujcv+tC5NO5b6s/q6gcjyu3ZeGaw8IxKiIiIiMjEzNDB\nsYiM4/VA23R3ohbcvnYry8/5+XR3Q2rYmo+fOd1dEKk5GhyLyCju/qfp7oOIiMh0qeHBcbV0gnI6\nRTn9oJhyHWV1ab3insKaxI/d+99x9eb7UsstWd38xUsAOGjJMgCaB+ZmdbdedxsAfQNRd8iCl2V1\ns44+GID29uasbHg4+jBQPyvus/nxrK6hFP1qJtZMbva+rG6EWH95oPzrLGSN5PPvtL7xTGZmZwEv\nBo4HDgSGgNuAL7j7NyrOvQo4xT1ftNvMVgNXAucDlwLnAs8C5gEr3H2Nma1Jp68EPgK8DJgPPAhc\nBFzoxa0nx+7rEcCbgD8DlgFzgHXAL4EPufujFecX+/ajdO9nA03AH4D3ufv1Ve7TALyZiJQ/mXg/\nvAf4KvB5d1dOkojIDKQJeSIzwxeIgeZvgQuA76TvLzGzD0+inWcB1wAtwNeAf2d0knsT8GvgjHSP\nLwNzgf8HfG6C93g5cDbwCPBt4ELgTuBvgT+Y2ZIxrnsacH3q21eAnwEnA1eY2ZHFE82sMdX/W+rf\nt4AvEe+JF6bnJSIiM1DtRo6tStBnh+XdfIevSyNxXcfBz8xq5sw/LM7YsgGATT1bsrqDVsRkO2uZ\nD0D/xg1Z3cYrbgFg7aMxua/xvquzun47CYBVT35KVtZWH1HhwW0RMW5ae29WN9h9PwA99U+kkw/K\n6lqXvDC+qI80UfP6wnOO52VVfh6KJc8ox7j7A8UCM2sCLgPOMbOL3H1t9UtHOR04292/OEb9gUSk\n+Bh3H0j3OZeI4L7NzL7r7r/dyT0uAT5Tvr7Q39NTfz8IvLXKdWcCb3T3iwvXvIWIWr8TeFvh3A8Q\nA/jPAe9yj0UPzayeGCS/ycy+7+4/3klfMbMbx6g6amfXiojIvkeRY5EZoHJgnMoGichpA3DaBJu6\neZyBcdn7igNbd98MlKPTb5xAX9dWDoxT+eXAHcSgtprrigPj5GvAMHBiucDM6oB/IFI13l0eGKd7\njADvIT4tv2ZnfRURkdpTu5HjXdQwEp8XRuras7LheZEDzLxYRm14XZ6PPNAWS6y1tkQcdvEBB2Z1\nTzsmosPX/O5SADY89mBWN28wNgTZMFIIovU/DEDf1nsA6O5Zn1X1bOkFoCVtUjJ72QuyugOXpEhx\nOUqcp4qyxxerlf2CmR0CvJcYBB8CtFacMlaqQqXf76R+mEhtqHRVOh6/sxtY7FTzGuAsIn95HlD4\nc8ioNI6i/6kscPchM3sitVF2BNAJ3Ad80KpsGAT0AUfvrK/pHquqlaeI8gkTaUNERPYdGhyL1Dgz\nO5QY1M4j8oUvB7YCI8By4A1A81jXV1i3k/qNxUhsles6JnCPTwPvAh4nJuGtJQarEAPmZWNc1zVG\n+TCjB9fz0/FwYmLhWGZNoK8iIlJjNDgWqX3/SAwI31iZdmBmryYGxxO1sz9GLDCz+ioD5MXpuHW8\ni81sEfAO4HbgJHffVqW/u6vchx+6+8unoD0REakhGhxXGGqIHfLqCn9pbe2L3ega+iLNYfuGfIe8\n4e6Y6DZADwB92/MJeXNG7gBgaUukT9Z1bczqZrXGZL0Nd+dLyjb3x69jbn3cb/aC/K+6w0ueCoAt\njr/Sts1/clZX3xx/IR8uRV+sMCyxlFZu2cS84p+QNSVvhnhSOv6gSt0pU3yvBuAkIkJdtDod/7iT\n6w8l5kJcXmVgvDTV7667iSjzM82s0d2HpqDNqo5Z0sGN2qRBRGS/ogl5IrVvTTquLhaa2RnE8mhT\n7WNmlqVpmFknscIEwNd3cu2adDw5rRxRbmMWsSzcbn+gd/dhYrm2A4HPmlll/jVmdqCZPXmHi0VE\npOYpclwhzcejvi7fZGPzvVcAsP72CLxt6son1jU1RrS2kQjXdvcPZ3UDdXMAePqqmMi3uT//N3j7\nlhg7bO/vzMoOnHNcaisWFugYyZdfa0gTBNvmxb/X9W152uVgKe7p5ehw4flY+q4cMS5Gjl2B45ni\n88QqEf9pZt8HHgOOAV4AfA/4qym81+NE/vLtZvYToBF4BTEQ/fzOlnFz93Vm9h3gVcDNZnY5kaf8\nfKAfuBk4bgr6+WFist/ZwIvN7DdEbvMiIhf52cRyb3dOwb1ERGQ/osixSI1z91uBU4lVJM4k1gie\nQ2y2cdEU326Q2NnucmKA+xYix/edwN9PsI2/AT5KrKjxdmLptp8R6Rrj5ixPVEqleCmxO949wJ8T\nS7i9gHhf/Bfgm1NxLxER2b/UfuS4uFutl6On8W217Nu6FKytS1syA7TOXg5A09zYsGNWYx7tnTs3\nVojqmBNlN9yYR5WPPGY1AMcdvxKAtVu6s7rLf/ZTAPrq8jzkDQMRHT52RQTGmpfmG4S0zjsivmhZ\nAEAhqIxnn3FGdnheWspNANL2yc8bo9oqzl1d5fqrKs8b515biUHt23dy3ppqbbp7LxG1/UCVyybd\nN3dfPka5ExuOXDJeP0VEZGZR5FhEREREJNHgWEREREQkqdm0ijov7ViWkgzqUnpFnRfPH32klO8Z\n0LYollE7fFEsrRa77oaGhvgR1tXF+XO7r83q2pccHk3NidWnOprySX4nvSgm682enf8KHrkv5v7M\nbo2yJU/J/wo+OBzPZ2QkJt+VSvl6bXVpCbeGlELihSfm5bSSdChOyBtjZzARERGRGatmB8cisneN\nldsrIiKyP6nZwXG1mOjE4qTl2Xp59HWEiNaOWGSh1NW3ZHVD5SXS0nVPP+lZWV1DfUST+4cG03V5\nNHrpiogqFyPcHW2xs+62rbEL7tBwHqH2Ulqmzast1zb66Fachlc5Ja8YOUZERERECpRzLCIiIiKS\naHAsIiIiIpLUbFrFripPYPPC+sjliWt1WQpFrq4iraK1ZYedaPM2C2VDaaHiYlldYxsAbZ1p591S\n8bNLeUZdqdzoRJ5OljuRpVCYVj4WERERGYsixyIiIiIiiSLHY6gWOR73fHaMOFcaFXFOE/GKC845\n9aPK6hlvYt3ElPvuVa/XjDwRERGRIkWORUREREQSRY6nSb0PAfnGJAAlylFeEREREZkOihyLiIiI\niCQaHIuIiIiIJDWbVlFtYpxnu9HZDufkX8fnheIkvHx5t7RDXpWPFONPfKty/qipeKms3D+30cdo\nuNyZcdocfYzLSql/PuqYbjihvorsTWa2BrQdtYiITA9FjkVEREREkhkWOY5jHj2tK9SVI6zsUFeO\n2pajsMXocNbmJJdFs/Gi1+lYKlWLXqdjqRB5rqwb1WZaMi6LmhfqqkSvRWTq3L5263R3QUREJkmR\nYxERERGRpIYHx6UqD2eshdLMbOzNPoxRibylkmcP94pHaWKPUqlEqVTa8Xp3SunhXsoe455fKo35\nGO/ccl9E9jYLf29md5hZv5mtNbPPmVnHONe82syuNLOudM1dZvZBM2se4/yjzOxiM3vEzAbN7Akz\n+5aZHVnl3IvNzM3sUDP7BzO71cz6zOyqKXzaIiKyH6jZtAoR2addALwDeBz4EjAEvAR4BtAEDBZP\nNrOvAW8EHgV+AHQBzwQ+DJxmZs939+HC+S8A/gtoBH4K3A8sBV4OnGlmp7r7TVX69f+A5wA/By4F\nRqbo+YqIyH5Cg2MR2avM7CRiYPwAcKK7b07lHwCuBA4EHi6cfxYxMP4h8Bp37yvUnQecC7ydGNhi\nZvOAbwO9wHPd/c7C+ccANwBfAU6o0r0TgOPd/aFJPJ8bx6g6aqJtiIjIvqN20ypsJD2G8wcjFANB\n1VIU8kep8Igyyg/yx/htjP0YLxWiNDJCaWSE4i3zx9htVrPDeVX+E9nL3piOHykPjAHcvR94X5Xz\n3wkMA28qDoyTDwObgNcUyl4PzAXOLQ6M0z1uB74MHG9mT65yr09OZmAsIiK1R5FjEdnbyhHbq6vU\nXUvhE6yZtQErgY3Au8aYFzAAHF34/lnpuDJFlisdkY5HA3dW1P1+vI5X4+6rqpWniHK16LSIiOzD\nanZwXCqV/30tREbrrFwZ39YVl3IrL4O2Y1vZ0m/pcitMYhtrDt/OVF12jYo+eGmH86t9X/66lJ5X\nqbTjdfkScIXrNBlPpkd50t0TlRXuPmxmGwtF84j/8xYS6RMTMT8d/24n582qUrZugvcQEZEaVbtp\nFSKyryov/ntAZYWZNQALqpz7R3e38R5Vrlm5k2v+vUrf9IlRRGSG0+BYRPa28ioRp1SpOxmoL3/j\n7j3AHcBTzKxzgu3fkI7P2eUeTpFjloy5Mp2IiOyjanZwXCqN7PBwj0ep/BjvnHHLxplMN8mHFx8j\n8cjuM1J4VOnrRB4jI8OjHqPqSsOMlIZ3/sMUmVoXp+MHigNeM2sBPlbl/E8Ty7t9zczmVlaa2Twz\nK+b2fp1Y6u1cMzuxyvl1ZrZ617svIiK1rGZzjkVk3+Tu15nZhcA/ALeb2ffJ1zneQqx9XDz/a2a2\nCngb8ICZ/RL4E9AJrACeSwyIz07nbzKzVxBLv91gZlcQ0WcHDiYm7M0HWvbwU11+1113sWpV1fl6\nIiIyjrvuugtg+XTc28ZaAkxEZE+xWHbi7elxKLEc2w+B9wO3ALj78opr/pwYAJ9ILNW2mRgkXw58\nw93vrjh/OfBPwBnEoHgQeAz4A/ADd/9R4dyLgTcAK9x9zRQ9xwEiReSWqWhPZA8or8V997hniUyP\nlcCIu1fdBXVP0uBYRGQPKG8OMtZSbyLTTa9R2ZdN5+uzZnOORUREREQmS4NjEREREZFEg2MRERER\nkUSDYxERERGRRINjEREREZFEq1WIiIiIiCSKHIuIiIiIJBoci4iIiIgkGhyLiIiIiCQaHIuIiIiI\nJBoci4iIiIgkGhyLiIiIiCQaHIuIiIiIJBoci4iIiIgkGhyLiEyAmS01s6+Z2WNmNmBma8zsAjOb\nNx3tiFSaitdWusbHeKzbk/2X2mZmrzCzC83sGjPrTq+pb+xiW3v0fVQ75ImI7ISZHQZcDywCfgzc\nDZwInArcAzzb3TftrXZEKk3ha3QNMBe4oEp1j7t/aqr6LDOLmd0MrAR6gEeBo4BvuvtrJ9nOHn8f\nbdidi0VEZojPE2/E73D3C8uFZvZp4N3AR4Cz92I7IpWm8rXV5e7nTXkPZaZ7NzEovh84BbhyF9vZ\n4++jihyLiIwjRSnuB9YAh7l7qVA3G3gcMGCRu2/f0+2IVJrK11aKHOPuy/dQd0Uws9XE4HhSkeO9\n9T6qnGMRkfGdmo6XF9+IAdx9G3Ad0AY8cy+1I1Jpql9bzWb2WjN7v5m908xONbP6KeyvyK7aK++j\nGhyLiIzvyHS8d4z6+9LxiL3UjkilqX5tLQYuIf48fQHwG+A+Mztll3soMjX2yvuoBsciIuPrSMet\nY9SXy+fupXZEKk3la+vrwGnEALkdOBb4IrAcuMzMVu56N0V22155H9WEPBEREQHA3c+vKLodONvM\neoD3AOcBL9vb/RLZmxQ5FhEZXzkS0TFGfbm8ay+1I1Jpb7y2LkrH5+5GGyK7a6+8j2pwLCIyvnvS\ncawctsPTcawcuKluR6TS3nhtbUjH9t1oQ2R37ZX3UQ2ORUTGV16L83QzG/WemZYOejbQC9ywl9oR\nqbQ3Xlvl2f8P7kYbIrtrr7yPanAsIjIOd38AuJyYkPT2iurziUjaJeU1Nc2s0cyOSutx7nI7IhM1\nVa9RMzvazHaIDJvZcuBz6dtd2u5XZDKm+31Um4CIiOxEle1K7wKeQay5eS9wUnm70jSQeAh4uHIj\nhcm0IzIZU/EaNbPziEl3vwUeBrYBhwFnAi3ApcDL3H1wLzwlqTFm9lLgpenbxcAZxF8irkllG939\nn9K5y5nG91ENjkVEJsDMDgY+BLwAmE/sxPRD4Hx331I4bzljvKlPph2Rydrd12hax/hs4Hjypdy6\ngJuJdY8vcQ0aZBelD1/njnNK9nqc7vdRDY5FRERERBLlHIuIiIiIJBoci4iIiIgkGhyLiIiIiCQa\nHO+HzGy5mbmZKWFcREREZAo1THcHppOZnUWslfcjd795ensjIiIiItNtRg+OgbOAU4A1xFI1IiIi\nIjKDKa1CRERERCTR4FhEREREJJmRg2MzOytNZjslFX29PMEtPdYUzzOzq9L3rzGzq81sUyp/aSq/\nOH1/3jj3vCqdc9YY9Y1m9mYzu8LMNpjZgJk9bGaXp/Id9rsf514rzeyJdL9vmNlMT58RERERmZCZ\nOmjqA54AOoFGoDuVlW2ovMDMPgv8A1ACtqbjlDCzJcDPgONSUYnYsnMxcAjwfGK/8Ksm0NZJwM+B\nucAXgLdru08RERGRiZmRkWN3/667LwauT0XvdPfFhcfTKy5ZBfw9sSf4fHfvBOYVrt9lZtYM/JQY\nGG8E3gDMcff5QFu69wWMHryP1dbpwK+IgfEn3P1tGhiLiIiITNxMjRxP1izgY+7+oXKBu3cTEefd\n9TfA8cAAcJq731q4xwhwU3qMy8xeDnwbaALe5+4fn4K+iYiIiMwoGhxPzAjw6T3U9uvT8evFgfFk\nmNkbgS8Tfwl4m7t/Yao6JyIiIjKTzMi0il1wv7tvnOpGzayRSJsAuHQX23gX8FXAgddrYCwiIiKy\n6xQ5npgdJuhNkU7y38GfdrGNz6Tjh9z9G7vfJREREZGZS5HjiRmZ7g6M4zvp+E9mduK09kRERERk\nP6fB8dQYTseWcc7pqFK2uXDtsl289+uA/wLmAL80s+N3sR0RERGRGW+mD47LaxXbbrbTlY5Lq1Wm\nDTyOrix39yHgxvTti3blxu4+DLyKWA5uLvArMzt2V9oSERERmelm+uC4vBTb3N1s57Z0PN3MqkWP\n3w00j3Htf6TjWWb21F25eRpkvxL4BTAf+LWZ7TAYFxEREZHxzfTB8R3p+HIzq5b2MFE/JTbpWAj8\nh5ktAjCzDjP7AHAesateNV8FbiYGz1eY2evMrC1dX29mTzOzL5vZM8brgLsPAC8DrgAWpbYO343n\nJCIiIjLjzPTB8SXAIHAysNHM1prZGjO7djKNuPtm4Jz07SuBJ8xsC5FT/K/Ah4gBcLVrB4C/AG4H\nFhCR5G4z2wj0An8A/hZonUA/+lNbVwMHAr8xsxWTeS4iIiIiM9mMHhy7+93A84l0hK3AYmJiC5ep\nVAAAIABJREFUXNXc4Z209Vngr4AbiEFtHXAd8LLiznpjXPsI8DTgHcC1wDZiV77HgV8Sg+PfT7Af\nvcCfp3svBa40s0Mm+3xEREREZiJz9+nug4iIiIjIPmFGR45FRERERIo0OBYRERERSTQ4FhERERFJ\nNDgWEREREUk0OBYRERERSTQ4FhERERFJNDgWEREREUk0OBYRERERSTQ4FhERERFJGqa7AyIitcjM\nHgLmAGumuSsiIvuj5UC3u6/Y2zeu2cHxgctPdoAnHX96VjZ37nwAli2Ip+0MZXVmNup6L+V1peGo\n6+vvj2PflqyuvX0eANv7twHQ1jorq2uob4vrR+L6EYbzNilF2chIVjY0NJTuHee7530aGBhI944+\nbNu+PasbHI626tJO4EMD3Xmbw3Ge17cC0NzSnNW1tjUCcMOlXxz95EVkKsxpbW3tPProozunuyMi\nIvubu+66i76+vmm5d80OjkVExmNmy4GHgH9397P2wC3WHH300Z033njjHmhaRKS2rVq1iptuumnN\ndNy7ZgfHA/1bAdiycX1WNrstorql4YjQWl0eHcZGp197iuwClKwJgKGRiPy2zm7L6tra2gFoaInr\nrZDGXQ7HWn0K6RYiwU310WYxYD08HGX11rhDWyUfBKC3L6LCLZsHs7qOtrkA1DW0xDmD+Set3oGe\n1PfoQ6mUP6/h4TySLbIn7IUBqIiIyJSq2cGxiMh0u33tVpaf8/Pp7oaIyLRY8/Ezp7sLu0SrVYiI\niIiIJDUbOe7b/igAmzffm5V5aSMAI1sjfWH2nNlZXW9vLwAN9fVRUJfnO9Q3zgFgeDgmz5XIJ8Nt\nYlO0NStSGkru+XV18eO1lLLh5G3W1UdZXV0hDaOcY1HXlOrqC+dHu431kQrR1pb/6lpSmkf/UF3q\nbz4psL09pWp4SiHJu8fISOEbkSlmZucB56Zv32BmbyhUv5FYxeFK4Hzg0nTus4B5wAp3X2NmDlzt\n7qurtH8x8IbyuRV1JwLvAU4GFgCbgduAr7j793bS7zrgM8A7gB8Cr3H36ZkVIiIie13NDo5FZNpd\nBcwF3gncAvyoUHdzqoMYEL8PuBb4GjGYHWQXmdnfAV8ARoCfAPcBi4CnAW8Dxhwcm1kL8E3g5cC/\nAe9w99JY54uISO2p2cFxa2NETNvylcvYtPHB+CJWXaOpqTWr27gxosrl6O3wSD5Zb8mSwwDonBcr\nMt1z3y1ZnY/EfVYsPzjdY2NWV9eQIrn15WNTVtfYFF+PFCbItbdHBLi1PSLVXsh6aUzPp7z0W3//\nQFbXvW1bul9ErxubG7M6a0jLvKU+NBT6UNeQR6ZFppq7X2Vma4jB8c3ufl6x3sxWpy9PB8529y/u\n7j3N7MnA54Fu4DnufkdF/dJxru0kBtMnAee4+ycmeM+xlqM4akKdFhGRfUrNDo5FZL9x81QMjJO3\nEu9rH64cGAO4+6PVLjKzZcAvgMOA17n7N6eoPyIisp+p2cHx0GBERXs25xt21DVE1NWJyGrv9q6s\nrrcnvh4eijzcoeE8MtvZERt9lOZEpLm7a1NW19zUAcCmjRsAWLv2oayuNJzyhBsiGj1Y2PCjnIfc\nWJ9Hhw9YeBAATR2RC13flke2jfp0jF/ZYG9PVrd9y+a4rjnO75ibR4eb29P1LRH17u8vzMEcUeRY\n9gm/n8K2npmOl03imiOB3wHtwAvd/YrJ3NDdV1UrTxHlEybTloiITD+tViEi023dFLZVzmNeO4lr\njgAOBB4EbprCvoiIyH5Ig2MRmW7jLZvijP0XrrlVysp/Dloyifv/FHg/cBxwhZnNn8S1IiJSY2o2\nrWLQUwrF5keysvmLFgHQ2rEMgOG+DVld67ZYnq2f8gS2fNm1we2xzNvIQD+Q72AHUJ+WfqtrTEu5\nNeczAGd1rgCgLS2ntu7xh7O60nCsDGWep1oMj8Svw8vz9Ovy1A5Ly8A1NqX2C/0rp4lYOjY1FtI3\niOfY1hDjj41d+SIA/YMtiOxh5RfjrubwbAEOriw0s3piMFvpBmJVihcCd0/0Ju7+MTPrI5Zwu8rM\n/szdn9i1LueOWdLBjfvpIvgiIjOVIscisidtIaK/h+zi9b8HDjGz0yvKPwgsq3L+F4Bh4F/SyhWj\njLdahbtfQEzoewpwtZkdtIt9FhGR/VjNRo5pSJPSbDgrKu950dYcS6WVihtwLI2JdU1pObVFs/Mf\nzeGL4t/I+QsXAHDYsuVZXW9fRJVnz4+NNxY8lv97/Wh3nN+XJt11Nub/Li9ZEJPuFhyY/2W4HBUe\n7I82S4Xl5Hp6YgLe9p5Ytq27L9+IpJu4rrUtnkN9Wx45ritFtLuzKX4Og/PyqPf6vnzinsie4O49\nZvbfwHPM7JvAveTrD0/Ep4AzgB+b2XeJzTxOAlYQ6yivrrjfnWb2NuAi4I9m9mNineP5wNOJJd5O\nHae/F5lZP/BV4Ldm9jx3/9ME+yoiIjVAkWMR2dNeB/wceAGxC96HmeAqDmnliJcCdwCvInbEWwOc\nCDw8xjVfJnbG+xkxeP5n4C+ADcTGHju758XAa4nI9G/N7NCJ9FVERGpDzUaO5y08AICt6x/Pykqe\n8oMtoqnelH82aO2Iv8C2z4m5OAcfmKdInrH6aQB0zI2Ic09vvpPswHC0Rcrp7dneltV976cx8f3+\nJ9bH/Tzf1nnrSCy79vRVL8/K6htj3bW6UuQaNxV+O8PDkSvc39eT7pNHjh9f+xgAjz0Qm5y0debR\nYYZSn1Mic2tbHo2u785zrkX2FHe/H3jxGNU2Rnnx+p9QPdJ8VnpUu+Z3wP/aSbtrxrq/u38b+PbO\n+iYiIrVHkWMRERERkUSDYxERERGRpGbTKo5fdTwAV//isaysyeIvqGaRtrC9lKcfNM6KiXSPrI+U\nie2b8p3ubCR2oGttj7SH5tZ8CbT2jlmpzZgUd/DcxVnd0w+L1Iw7bvgdAL11+Y97sDUm7990a75X\nQWfn8mhzdlqarbAkW51FGkZjY6RJtC7I0z4O64iVrtbcH+kbm7fly8aW0oT7DZviec2v25zVrTyy\n2kpYIiIiIjOXIsciIiIiIknNRo67NkcUleF8I4269PVAfyxhNnvJsVnd0KzYUMu33gNAY31+3a8u\nvQyArd3dAFh9HrVdfvjhqfGIIM9tyK97wQtPAqBvMMq2bMsn0bUeEEur3XfnrVnZgs6IIi89JKLP\ndU15ZNuyqHd8nmmoy+cRNaT+tM6OZeEeXf9ofp/ZEe1ubG5JP448cnzIEUcgIiIiIjlFjkVERERE\nkpqNHG9+PJZwGxrM82+HhiKH1xpjubZ5B+Y5t2s3dwHQ2RLLm80rRIBvW7cOgMGhWAatVMo3Frk/\nbdgxMBT3OWjR7KyusS32GmienbaW7tqS1dWVIvJbX/h8snF97DWwZfOa6Gfx15O2mba0vfWoFajS\ndtZ922ODkL7B7qxqbn3kHC8/OKLETSP5xh/f+vkvADj3vW9CRERERBQ5FhERERHJaHAsIiIiIpLU\nbFpFU12kRSw8YH5W1jcUu9kNlSIVoq4hXyrN+mMy3CGz0u55/YNZ3ZBFykTrrFhOrWdbV1bXsy1N\ncEsT5YYG87SFeo/Uh7aGuF9f/xNZXXPaWa+zY2FW1j47lmQbTlkbpVLelqUd7ihFaofX5Wkfg4Ox\na97Gx2I3Xac//zm0xNJvj2yJ57Bi6VOyusbuPyEiIiIiOUWORURERESSmo0cz18Yk+AOPfywrOzq\n314LwIP33QDAoicdmdV5d0RdZy+NH8k9D+dR3oGRCOUO90XUFssnw5Vjzw2NsQnIwGAe0fXh2Hij\nozV9Bhnqy68bjGhy7/Y8Cj0wlJZuq49l4YZG8smEdUTkeFZbnDNMc1bX0xf3NCKyXe+l/LoUcO6z\n+OKJDT1Z3RHLjkdEREREcooci4iIiIgkNRs53rRhKwC92/MIa3tbJwDbt8eSak88eENWV58SfQ/o\njI1BrtqwMavztOFGaSTixA2FyPGypZEn3Ln4QADmz8rzhDtSjnJHe9puejCPHA/1RsR4eDiP5K7f\nGNHkjgXRptcXIsBEdLihJTb88FL+uaZUigizW7TZ3Lwp/0FYbAzS1NCa7ptXDfcVloMTEREREUWO\nRWTfZGZuZldN4vzV6ZrzKsqvMjMf4zIREZFRNDgWqRGTHUyKiIjIjmo2reKoI1YB8MBDj2ZlnmJH\nDSlN4qE7bsnqXnTaKQC0pxQIt/qsbnZ7TJDr64q0hec+86Ss7u/+5iwAWjvjnNbCT7S5OSbwNbZE\nqkXnvI6sbsiiztIRYMVhMXlw4QGHRl1d3lh9XaRkNDakdd4sT99YMncBANs7Yme8trZ8KbeNXZFW\nsqkrfg7dvfkEwAe3lp/jGxCpAb8HjgY27uxEERGRsdTs4FhEZhZ37wXunu5+iIjI/q1mB8fvfe97\nAfjYJz+elT3y+L0AzJrVDsCWzfnstIMWxmQ9UlS5saU9q/PB2OjjoAWLAPiL578wq2sYinB0CxHR\nbW7II87DpZjAZ/UR5Z0ze3ZW11cfS7Jt78kjuXPTRLz29vXRlcYthbYiKmyWNikpFTb6aE/LvB0S\nZf39LXnfu+LrpqG4vrvnvqxuU3cjsveY2VnAi4HjgQOBIeA24Avu/o2Kc9cAuPvyKu2cB5wLnOru\nV6V2v56qT6nIrz3f3c8rXPuXwN8DK4Em4H7gW8Cn3X2gcF3WB+AY4MPAK4AFwD3Aee7+IzNrAN4L\nnAUcDKwFPuPun6vS7zrgzcDfEBFeA+4EvgZ80b2wBuHo6w4CPgGcAcxO1/xfd/9WxXmrgSsrn/N4\nzOwM4J3AiantR4H/Aj7i7l3jXSsiIrWpZgfHIvugLwB3AL8FHgfmAy8CLjGzI939X3ax3ZuB84kB\n88PAxYW6q8pfmNlHgfcRaQffAnqAFwIfBc4ws9PdfZDRGoFfAZ3Aj4kB9auBH5jZ6cDbgGcAlwED\nwCuBC81sg7t/t6KtS4C/Bh4BvgI48DLg88DJwGuqPLd5wPVAF/EBYC7wl8A3zWyJu/+fnf50xmBm\n5wLnAZuBnwHrgacC/wS8yMye5e7dE2jnxjGqjtrVvomIyPSp2cHx+o0bADj52SdnZT3b4t+5W26L\nv7zObs8jpx1zU8Q3Hdpa2rK68tdnnvE8ANrr86jyvTfGttMHHxP5xAuWtmZ1pYbysmtx7B8YzuqG\nW6Osty+PXj/0wJ0ALGyNgNXCZY9kdQ9vj4jviEfucUMpDw42kqLXadm2rd1H5M+5N7aLbm2Pbaq9\nZ3NW19yQR59lrzjG3R8oFphZEzGwPMfMLnL3tZNt1N1vBm5Og7011aKmZvYsYmD8CHCiu69L5e8D\nfgj8OTEo/GjFpQcBNwGry5FlM7uEGOD/J/BAel5dqe7TRGrDOUA2ODazVxMD4z8Cz3X3nlT+QeBq\n4K/N7OeV0WBisPqfwKvKkWUz+zhwI/ARM/uBuz84uZ8YmNmpxMD4d8CLilHiQiT+fODdk21bRET2\nb1qtQmQvqRwYp7JB4N+ID6qn7cHbvykd/7U8ME73HwbeA5SAvx3j2ncVUy7c/RrgISKq+97iwDIN\nVK8DjjErzGrN739OeWCczt9OpGUwxv1H0j1KhWseAj5LRLVfN+YzHt870vHvKtMn3P1iIhpfLZK9\nA3dfVe2B8p9FRPZLNRs5FtnXmNkhxEDwNOAQoLXilCV78PYnpONvKivc/V4zexRYYWYd7r61UN1V\nbVAPPAasICK4ldYS7y2L09fl+5copHkUXE0MgqvtZ/6nNBiudBWRRrKre6A/i8j5fqWZvbJKfROw\n0Mzmu/umKvUiIlKjanZwfO011wMwZ04+Ce7YY44DYKA3gmBzZuXzfzrmRaqENcSP5Mw/OzGrGxmJ\nZeGOWBpjl951eTrC4EAExwYHo63evnwXvJ7BSKPYsD4m2Bl5WgXD0YeFC+YUeh19WDQ70iSWzs53\nz+vfFqkdpca21Kd8XDXQF30oDUTZSHeeEjLcE20Mz46Ui8aWzqxu+dJ890DZs8zsUGKpsXnANcDl\nwFZiULicWE9vT/5CyusIPj5G/ePEgH1u6lfZ1uqnx4u5YiA9qo6I7Bbvv7lKTjPuPmxmG4FFVdp6\nYoz7l6PfHWPU78x84v3v3J2cNwvQ4FhEZAap2cGxyD7mH4kB2RvTn+0zKR+3crHpEhG9rGbuLty/\nPIhdTOQJVzqw4rypthXoNLNGdx8qVqQVLxYA1Sa/HTBGe4sL7e5qf+rcvXOnZ4qIyIxSs4PjurQk\nW3d3d6EsUqxPenZEhQ8+ZGFWNzQcE+PaW+JH8rSV+V+4f/TTywB48M7YNOTPn/eyrG5wOCLGdc1x\n3UhhEa3BwVjKrS9Fk1sa8xTMxsaoWzgrjyZbXUSku7uiLw915ZP1GvpiLLDmiQikrd+2PatraY++\njvRGX7Z3P5zV9Q3EpL7lx8ZGIUsX5mOB1ro8Mi173JPS8QdV6k6pUrYFeGq1wSTwtDHuUSKbUrqD\nPxKpDaupGByb2ZOApcBDe3D5sj8S6STPBa6oqHsu0e+bqlx3iJktd/c1FeWrC+3uihuAM83sKe5+\nxy62ISIiNUgT8kT2jjXpuLpYmNbZrTYR7ffEh9c3Vpx/FvDsMe6xiVhruJqvpeMHzSz7VJgmzX2K\neC/46lidnwLl+3/MzLK8n/R1eTHyavevBz6R1kguX7OCmFA3DHyjyjUT8Zl0/HJaR3kUM2s3s2fu\nYtsiIrIfq9nIscg+5vPEQPc/zez7xIS2Y4AXAN8D/qri/AvT+V8ws9OIJdiOIyaS/YxYeq3SFcCr\nzOynRBR2CPitu//W3a83s08C/xu4PfVhO7HO8THAtcAurxm8M+7+LTN7CbFG8R1m9iNineOXEhP7\nvuvu36xy6a3EOso3mtnl5OsczwX+9xiTBSfSnyvM7BzgY8B9ZnYpsQLHLGAZEc2/lvj9iIjIDFKz\ng+NyKkM5lQLALFIttqU/Uo9YYbGAkUhhKJXi/G3b88l6j66JVAYj0hDmLLKsrm1utLGlJ1Iiutbl\n6Q6bt0Q65OBg3LCrq5BSWR9l3T35fKPBkTR5LvWlcTjvw5K5Eezb2hvzmfot3wWvvynmC/Vt7UrP\nOZ8UmJZYZnDbGgBmz87TVU845inI3uHut6a1df8VOJP4f+8W4OXEBhd/VXH+nWb2Z8S6wy8moqTX\nEIPjl1N9cPxOYsB5GrG5SB2xVu9vU5vvNbM/EjvkvZ6YMPcA8EFix7kdJstNsVcTK1O8CXhLKrsL\n+L/EBinVbCEG8J8kPizMIXbI+1SVNZEnxd0/YWbXEVHok4GXELnIa4EvERuliIjIDFOzg2ORfY27\nXw88b4xqqyxw92uJfNxKtxIbWFSev57YaGO8PnwH+M7O+prOXT5O3epx6s4itpOuLC8REfTPT/D+\nxZ/Jaydw/lVU/zmuHueaa4kIsYiICFDDg+ORkZFRR4D+/hTdTRPl6m76fVb31EURMW5vXgpAQ8uC\nrO7lL3sRAHM6YqWtto58ebgf//gXANzwh9sB2Nq1JavrSZPmurbEcWgoD8yNlCLa29iUr941qyNS\nMRelKPHcjnzC4MHLVgDQ2hTn3HRjvrxsY0M8n+NPjiXnrrrmqqxuS0/cs3dDzDlqrzskq7v1lm3p\nqzcjIiIiIpqQJyIiIiKSqdnIcWtr5AIPD+dLpd18880AeENEXzvn5VHlQY88386F8wGY1ZYvMdt5\ndESTW9tiw45LL8v/CvuVr3wPgIHBtLtu4Y+6zU2RF1wqxfpuc+bnEecDDohlZee05dHh+fNjSbam\nlCe8bTBfyu2JFIXu3vAnALo2r8/qTn3OSgBOOP5QAG5PS84BHLws7nP8CbEByuBg/nnozru1u62I\niIhIkSLHIiIiIiKJBsciIiIiIknNplWUl21raMifYlNTpEqseyImw9UdfGRWt6klJuv1bo4JbI33\nrM3q5syL6xqbNgPwi8t+ndUddFDsXLd40TwAHnjg0ayufyCWYhsaiWXb5nbmk/wWpLSKDevz5d22\nPLwGgJGhSNEoeZ4SMpw2SevvS0vFNeQpIQ0tjQA8tiGe15w587K6pz099jH4X38Zu/p1deW77T79\n0WMRERERkZwixyIiIiIiSc1GjsubfxQ3ATnqqKMAuPfBSwH4ya/yCPDKI2Iy28qnR9R12ex8k43O\n+eWo8H0AdG3dnNW96U2xrOzRRzwJgG9/+0dZ3WWXXxl9SBPstm/PNwh5+E+PANDc1J6VzZ4dE/Z6\neyJivG1bT1bX2xvLrpUjx42N+XPt6Y/z122M860x252XjnmdALS2RtnQ0FBW19RUs79+ERERkV2i\nyLGIiIiISFKzocPHH38cgG3btmVl3d2R39vbHxt1bOvKl0q76bYHATj2GbHk2cHLDsrqSmnzjrvv\nvheAOXPyJdnaZ0U+cm9ftH34EYdldZf/OiLH/YORz9zQny8PV2cR+m1ryqO8G9dHn7s2R//6+vJI\n8/Bw2kDEI9d4uLE+q7vr7uj7McfEkm7POeW0rG7JwbE83Nq1a3fo+8qVKxERERGRnCLHIiIiIiKJ\nBsciIiIiIknNplX85Cc/AaCvry8rK09GG7ZIczDyWW39I5GucOttdwEwOJRfV17+7MorrwFg8QFL\ns7qW1mYANm/uAmD79jxVo74+frz1I3Hs3ZanSWzbEuke6x75U6HXXr4SgLlzO7OaRYsOBmDp0lgC\n7ogjj8jqjn7yMQAct/IEAFasWJHVtbZF/xrqo013z+p6e/O+ioiIiIgixyKynzGzNWa2Zrr7ISIi\ntalmI8ddXRHJTXuBjDYcnwlK5JtsbOvZAMB/X/ffANz8Pzfndb0x2W5wMKLL9TYrq1v3+BMAHLos\nlnL7402XZ3Xbt8dmHiMem4E0NecT8hYujuXhDjnk4KxsxaHLAXjSobE5yfErj8vrDlsGwKKFsZHI\nrNn5RL6Gumi3rzci493burK6tZtiIl7X1oha9/bmEfFSipYvOeiFiIiIiIgixyIiIiIimZqNHKcU\nW0qlUlZWzrfNg8l5XXmptC1bI/ra3NSaX1cfnyE8bSiy9on1Wd2PfnIFAIctfwiArT15Hu/JzzkZ\ngGOeGjnBTz3mKVnd4U+KSHMxcjx/wXwAGuojEjzYP5jVdfdENHjDE+sAuOfefBvobSlCXRqO59PQ\nkD/D9vbIq26fMweABQfMz+paW/INSEREREREkWMR2QdZ+Hszu8PM+s1srZl9zsw6xji/2czOMbPb\nzKzXzLrN7Boz+8tx2n+nmd1Z2b5ymkVEZraajRyLyH7tAuAdwOPAl4Ah4CXAM4AmIPuzipk1Ab8E\nTgHuBv4NaANeAXzXzI5z9/dXtP9vwFuBx1L7g8BfACcCjel+IiIyA9Xs4Ng9JtuNmo9nKa2inHIx\nki9rVvI4cyRN0htiJKtbtCh2y5s9O3aXa25uzuqOPOJwAE5cFcuovfXtx2Z1hx8ey611pJQGK6Rx\nbO/pAWBz2g0P4KGHIjWjvKvf8FA+YbAc429IKR7Ns/JJgQuXLgZg/ty50c+2PCWksSEt4VYXz3Vo\nKO9Db0rHENmXmNlJxMD4AeBEd9+cyj8AXAkcCDxcuOQ9xMD4MuAvPP3Pb2bnA78H3mdmP3P361P5\nc4iB8b3AM9y9K5W/H/g1cFBF+zvr741jVB010TZERGTfobQKEdnXvDEdP1IeGAO4ez/wvirnv4lY\nJPwfywPjdP564MPp278tnP+GQvtdhfMHx2hfRERmkBqOHPuoY1FdmljX3NKSlS1atAiAzs7YeKNj\n3rys7vmnnwHASc8+CYCG+vzHNjwS/xY3pRmAxU1H7rzzTiDfbKNvIK8rLzHX1pYvyTanI9IpDzw4\nItWthQjw7FkRfS5PohupyyPANMRzbKqLyXd1nn/mGR6M/m3bGn3o3Z73oRy1ftLyZYjsQ05Ix6ur\n1F0L+Z91zGw28CRgrbvfXeX836Tj8YWy8tfXVjn/Biis8TgB7r6qWnmKKJ9QrU5ERPZdihyLyL6m\nPOnuicqKFBneWOXcx8doq1w+d4LtjwCbJtxTERGpOTUbOV64cCEAra159HVeigaXo8TlcwAOOiii\ntXNSXnFdQ/6jOfapTwXglGc/a4f7XHV1bCl9zfXXA6Pzkcv3K7d92OLD87r5UVeMHDc1xRJuDXUR\nVvaRPDo8mCLAw8MpaDZSWJCuPyLH2wdjW+z+7f1Z3brHHgNg7drIZ77//vuyusceiw1CTnnujs9L\nZBqV1yk8AHiwWGFmDcAC4NGKcxeP0daBFecBdI/Tfj0wH1g76V6LiEhNUORYRPY1N6XjKVXqTgbq\ny9+4+zZi4t4SMzu8yvmnVrQJ8MdCW5WeSQ0HDUREZOc0OBaRfc3F6fgBM+ssF5pZC/CxKud/jViY\n5v+kyG/5/AXAvxTOKfuPQvsdhfObgI/udu9FRGS/VrMRkle96lXA6LSK9vaYzFZOXyhO1rM0Q67a\nRL777o15PosWxL/T5TQJgGXLDk5tR3rEvHnZv+XMSUu4NTXH/awh/yxSItofHsqXUy0v3TbQH6kT\ng/35UmtDw5Eq0b0tJtFt2pCnRW5ZH2Xr10UKRdemfAe/rV2RnumlmJA3a1b+83jKYfmkQ5F9hbtf\nZ2YXAv8A3G5m3ydf53gLO+YXfwp4Yaq/xcwuJdY5fiWwCPiku19baP9qM/sS8GbgDjP7QWr/xUT6\nxWMUt88UEZEZpWYHxyKyX3snsQ7x24G3EJPkfgi8H7ileKK7D5rZ84F/BP6aGFQPp/Pe5e7frtL+\nW4kNQ94CnF3R/qNEqsbuWn7XXXexalXVxSxERGQcd911F8Dy6bi3VVvqTERkJkp5y/cC33H3V+9m\nWwNEfvQtOztXZA8pb0RTbZlDkb1lV1+Hy4Fud18xtd3ZOUWORWTGMbPFwHp3LxXK2ohtqyGiyLvr\ndhh7HWSRPa28e6NegzKd9sfXoQbHIjITvQt4tZldReQwLwZOA5YS21D/5/R1TUREppMvP+AfAAAg\nAElEQVQGxyIyE/0KWAmcDnQSOcr3Ap8FLnDlm4mIzFgaHIvIjOPuVwBXTHc/RERk36N1jkVERERE\nEg2ORUREREQSLeUmIiIiIpIociwiIiIikmhwLCIiIiKSaHAsIiIiIpJocCwiIiIikmhwLCIiIiKS\naHAsIiIiIpJocCwiIiIikmhwLCIiIiKSaHAsIjIBZrbUzL5mZo+Z2YCZrTGzC8xs3nS0IzPTVLx+\n0jU+xmPdnuy/7N/M7BVmdqGZXWNm3ek1841dbGuffS/UDnkiIjthZocB1wOLgB8DdwMnAqcC9wDP\ndvdNe6sdmZmm8HW4BpgLXFClusfdPzVVfZbaYmY3AyuBHuBR4Cjgm+7+2km2s0+/FzZM141FRPYj\nnyfexN/h7heWC83s08C7gY8AZ+/FdmRmmsrXT5e7nzflPZRa925iUHw/cApw5S62s0+/FypyLCIy\njhThuB9YAxzm7qVC3WzgccCARe6+fU+3IzPTVL5+UuQYd1++h7orM4CZrSYGx5OKHO8P74XKORYR\nGd+p6Xh58U0cwN23AdcBbcAz91I7MjNN9eun2cxea2bvN7N3mtmpZlY/hf0VGcs+/16owbGIyPiO\nTMd7x6i/Lx2P2EvtyMw01a+fxcAlxJ+vLwB+A9xnZqfscg9FJmaffy/U4FhEZHwd6bh1jPpy+dy9\n1I7MTFP5+vk6cBoxQG4HjgW+CCwHLjOzlbveTZGd2uffCzUhT0REZAZx9/Mrim4HzjazHuA9wHnA\ny/Z2v0T2FYoci4iMrxzF6BijvlzetZfakZlpb7x+LkrH5+5GGyI7s8+/F2pwLCIyvnvScaz8t8PT\ncaz8ualuR2amvfH62ZCO7bvRhsjO7PPvhRoci4iMr7yO5+lmNuo9My079GygF7hhL7UjM9PeeP2U\nVwd4cDfaENmZff69UINjEZFxuPsDwOXEZKW3V1SfT0TZLimvx2lmjWZ2VFrLc5fbESmaqtehmR1t\nZjtEhs1sOfC59O0ubQcsUrQ/vxdqExARkZ2ostXpXcAziPU67wVOKm91mgYZDwEPV26yMJl2RCpN\nxevQzM4jJt39FngY2AYcBpwJtACXAi9z98G98JRkP2NmLwVemr5dDJxB/KXhmlS20d3/KZ27nP30\nvVCDYxGRCTCzg4EPAS8A5hO7OP0QON/dtxTOW84Y/yBMph2Ranb3dZjWMT4bOJ58Kbcu4GZi3eNL\nXAMDGUP6cHXuOKdkr7f9+b1Qg2MRERERkUQ5xyIiIiIiiQbHIiIiIiLJjBscm9kaM3MzWz3dfRER\nERGRfcuMGxyLiIiIiIxFg2MRERERkUSDYxERERGRRINjEREREZFkRg+OzazTzD5tZg+Z2YCZrTWz\nL5vZgeNcc6qZ/ZeZrTOzwXT8oZk9b5xrPD2Wp607/93MHjGzITP7UeG8RWb2f8zsdjPbbmb96bzr\nzexDZrZsjPYXmtnHzOw2M+tJ195uZh8xs87d+ymJiIiIzBwzbhMQM1sDLANeB/xr+roXqAea02lr\ngBMqd2gxs38FPpC+dWAr0AFYKvu4u7+vyj3LP+TXAxcBbcSWnY3AL939pWng+zugPDAfAbqBuYX2\n3+ruF1W0fTKx9WJ5EDwIlIhtQAEeAZ7v7veM82MREREREWZ25PhCYAuxf3c7MAt4CbGN5nJg1CDX\nzF5FPjD+HLDI3ecBC1NbAOeY2WvHuefngT8Ax7r7HGKQ/J5Udy4xML4feC7Q5O6dQCtwLDGQX1fR\np2XAT4mB8ReAw9P57emay4GDgf8ys/qJ/FBEREREZrKZHDl+AniKu2+qqH8P8CngIXc/NJUZcC/w\nJOA77v7qKu1+C3g1EXU+zN1LhbryD/lB4Bh376ty/Z3A0cCr3P27E3wu3wBew9gR6yZiMP5U4JXu\n/v2JtCsiIiIyU83kyPGXKgfGSTkHeIWZtaevjyMGxhAR3GrOT8flwIljnPO5agPjpDsdx8x3LjKz\nNuCVRArFp6ud4+6DQHlA/PyJtCsiIiIykzVMdwem0R/GKF9b+HousB04IX2/wd3vqHaRu99jZmuB\nJen8G6qc9rtx+nMp8AzgE2Z2ODGovWGcwfQqoInIfb4tgttVtabjwePcW0RERESY2ZHjbdUK3b2/\n8G1jOi5Mx7WM79GK8yttGOfaTwA/IQa8bwN+A3SnlSr+2czmVpxfjjAbcMA4jznpvLad9F1ERERk\nxpvJg+Nd0bLzU8Y1MlaFuw+4+0uAZwGfJCLPXvj+XjNbWbik/Lvb6u42gcfq3ey7iIiISM3T4Hhi\nyhHfnaUmLK04f9Lc/QZ3f6+7PwuYR0zy+xMRjf5K4dQn0nGOmXXs6v1EREREJKfB8cTclI7tZlZ1\nsp2ZHUHkGxfP3y3uvt3dvwO8ORWtKkwS/B9gmEireMFU3E9ERERkptPgeGJuJtYfBnj/GOecl45r\ngN9P9gZp2bWxlCflGZGTjLtvA36Qyj9kZrPHabvBzGZNtk8iIiIiM40GxxPgsRj0B9O3LzGzC81s\nPoCZzTezzxLpDwAfLK5xPAm3m9lHzezp5YGyhRPJNxn5Q8WufecAm4EjgOvN7AVm1li49igz+2fg\nHuBpu9AnERERkRllJm8Ccqq7XzXGOeUfygp3X1MoL24fXSLfPrr8IWNn20ePaq/inK7UFsTEva3A\nbPIVMzYCp7n7rRXXPZ1Ym/mgVDRErJk8mxRlTla7+9XV7i0iIiIiQZHjSXD3DwKnAT8mBquzgE3E\nEmx/Vm1gPAkvAT4GXAc8ltoeBG4F/n97dx5meVXfefz9vWttXUtvdLOEQhRoJKLggDEqMGo0DxOX\nxMTHmMyg44wkqBjNzKAmjxDGZdTxQcV5HCdBZzRRn4njY8Q1KhqBKIRNgWZraKCbpdfqrv1uZ/74\nnvs7v66+1fRSXdV9+/N6Hp5f9e+ce+653cWt7/3W95zzUfw0v1/OfVAI4VbgDOC/ADcDE/j+zFN4\nXfKngQsUGIuIiIg8s2MucywiIiIiMh9ljkVEREREIgXHIiIiIiKRgmMRERERkUjBsYiIiIhIpOBY\nRERERCRScCwiIiIiEik4FhERERGJFByLiIiIiEQKjkVEREREIgXHIiIiIiJRaaknICLSjczsEWAQ\n2LjEUxERORqNArtDCKcs9hN3bXD8vR/+QwBYu+q4dLPRAsCsCECrFbKmWr0OQAh+z0ht1mrENn98\noVjM2qZr3vblH94FwB2P7sraBgvevxX/mhuFctZWsL3nXKvV4nP744jPB1Au+2MbjXqHV2vxdfm1\nmJtfq9EEoNd6fMjc61o9VPW5X/ufO8xGRA7RYG9v7/J169YtX+qJiIgcbdavX8/09PSSPHfXBsen\nP3sUgFNGT043mx581v3C2K7JrGl8fByAYskDy4GenqxtWU8FgEopxpChmcYse4D5vfU7AGg8kSpV\nGhX/651ttYPkatZmwccqWIpLG+bjFs0D2GYzBcJW9jnUqO31WlNQ7M9diH0BGjHgnq7668nNnMKK\nCiJHGjPbCBBCGF3amRyyjevWrVt+2223LfU8RESOOueeey633377xqV4btUci4iIiIhEXZs5FhFZ\nandv3sXoFd9e6mmIiCyYjR+9eKmncNh1b3DciOUKzVRI0JidAmBy2ksNpqansrZW8HsFvLZ353hq\nKxRGAAixFKLUSqUNxfi4avD+lVydcCGW97aa7VriXGlvM9Y/5+qDS7HeuT3nEmmsWHFBobVnbbTz\nr4tFL9soW3ocBa+JLhRnAahZ+idvlXP9RERERERlFSKy+My9w8zuMbMZM9tsZtea2dA+HvMmM7vB\nzMbiY9ab2V+YWXWe/meY2RfN7HEzq5nZ02b2d2Z2eoe+XzSzYGbPMrN3mtkvzWzazH6ygC9bRESO\nAt2bOc4Wv6Wfm6Hl2d32Iri1x6/O2hoNz7DW42q9p7eOZW3bdvvCvdXD/QD05raaKMRFcE1rX9Pz\nNeIOEbPE7G0u2xuae+6cAWT7SBTj/NqZakhZ5Eb7mh+rvYtG+/G5+YU41kDcmaPVSs9XbKZFhyKL\n7BrgXcCTwOeBOvBa4HygAnuuPDWz64C3AJuArwNjwIuAq4GXm9krQwiNXP9XA/8PKAPfAh4CTgR+\nF7jYzC4KIdzeYV6fAl4KfBv4DnuuYe3IzOZbcXfGMz1WRESOPF0cHIvIkcjMXowHxhuA80IIO+L9\nDwA3AGuBR3P9L8ED428Abw4hTOfargQ+CFyGB7aY2QjwFWAKeFkI4d5c/7OAnwN/DZzTYXrnAC8I\nITyyMK9WRESONl0bHG9+chsAM7WUYR1Y1v4qZombKYv69NNPATA767W5/QMjWdv0jPffPLUdgBXD\nvVnbULkPgBI+VqWQEk09Rf962ofEQqpiqcXMcTNXV4z58xTbNcrF9DztOuJCy8es5zLiheB1yD2x\nyLmU28u4UfQa6krJn7taS89XJV+3LLJo3hKvH2oHxgAhhBkzex8eIOddjv9P+9Z8YBxdDbwDeDMx\nOAb+LTAMvCMfGMfnuNvM/hfwbjM7c2478LEDDYxDCOd2uh8zyp0CcBEROYJ1bXAsIkesdsD40w5t\nN5IrZTCzPuBsYBse0HYabxZYl/vzb8Tr2TGzPNdp8boOmBsc37KviYuISPdTcCwii6296O7puQ0h\nhIaZbcvdGsGPgFyFl0/sjxXx+h+eod9Ah3tP7edziIhIl+ra4LgV1+Y8/MiD2b2eWKUwPDgMwPRk\n7udg2POLRnMma9q+04+E3rzJf9t6/HGp5OLMMz1hVYqL4Hpyf6O98evdMRE2U0iNjVhyMVhOW8Zd\n8LwTAahNeR3GP9+/M2srF/w0u/ZWc6XcP13BvAyjt+ylHYViyq61F/xVemJ5Ra6UolzUqdGyJNpn\nrB8HPJxvMLMSsBJfeJfve0cIYX9LFNqPOTuE8MsDnJtqjUREjnFdGxyLyBHrdry04gLmBMfAS4Bs\nMUAIYcLM7gGea2bL8zXK+/Bz4PfwXScONDheUGedMMRtx8CG+SIi3aRrg+PjVvvqu18/azS7t2uX\nZ2IbNV+c1ltOSaLZmmdri/FQjtlGWrg2OenZ3ZNOOsnHXpW2Yu3piQdvxCxspZQW+fX1+lZppYkJ\nb8utvSvVPbN9xkhaWPf60UH/Ytgz25t335e1je2KC/jiASEzjZT1Lcbn7q14driVr8uMGe1C+2r5\nbejSXEUW0ReBtwEfMLNv5nar6AE+0qH/J4G/Aa4zs0tCCGP5xrg7xSm5rdm+AHwA+KCZ3RpCuGVO\n/wK+i8VPFvA1iYhIl+ja4FhEjkwhhJvM7DPAO4G7zezvSfsc78T3Ps73v87MzgX+FNhgZt8HHgOW\nA6cAL8MD4ktj/+1m9gZ867efm9mPgHvwkomT8AV7KwBt9C0iIntRcCwiS+Fy4AF8f+K3A9vxYPb9\nwF1zO4cQLjOz7+IB8Cvwrdp24EHyx4Evz+n/IzN7HvDnwKvwEosa8ATwY/wgERERkb10bXBcKXn5\nwdCy9BKL5ovTt2/3rVILpVTn0Ff2BW/tsoXxifGsbfmgr+Q7dfR4H3MglUJUq17K0BMXw/WU0/MN\nDfjjxiZ87JmpXBlH3PN4bNtEdu/RezcAsHXKf2s8WB5NLyjurTyNt4XcuV3lsp/cNxifb3I6HS5W\nm/WvZ+JezbVa7sRwLT2SJRJCCMC18b+5Rud5zPXA9QfwHBvxPZD3p+8lwCX7O7aIiHSvwjN3ERER\nERE5NnRt5tjiqXE00pZslYJ/FljW59ne2kzKDtMK8XGeTR6opqzy6rWrAeiv+mK2Yn0yaysUPYtc\njNu15bdHG+j30/P6er3PdD1t2zYbM86b0/R4IGaWz3+e71h1y01pIX950LPDszHb3ZvLUFfj131V\nz1C3mmnuM3XPHDfjvZnZetYWQm6FoIiIiIgocywiIiIi0ta1meNW3Cq1QKoPLsZtzPr7/GUXC6lw\nt17zjOpszTOt/SNpu7a+mJlttTzTavEgjjgqAKHpj7dcNrb9yaMSt1grFdJcrOV1z6VcpnnNs04B\nYN3znwvA83akTPOtGz3LPRufr0x6XDneq7a3ZutN85uc8VnUmn613GsuFVV0LCIiIpKnzLGIiIiI\nSKTgWEREREQk6t6yiuDbmjVDeom14KfghYKXE5R6cmcAlGKpRTzxrpDb56zWXuCWVTKkkobQLt8o\n9sTnTYv8Zme8dMJa7adIZRWFxi4A1gymEojzn3c6AP1Vn8uJa9dkbTffvx6AnqovzGvV8gvrwh7X\ngf7+rG3LWHs+7ZPy0ueh9ql5IiIiIuKUORYRERERibo2c9zOCU9Npm3Xdu7wU2nbydPh4ZGsrRCz\nw8V2NrXZyNqsHrO0sanYXvgGVGLG2ErL4nUsa2s14zZqsz5WJZdx7jffw+38556e3WvEwz8e3uDz\nrM+kOTRmPevdN+RznpqZzdrq9ZRFBqjmMuLtbHIrHm5ilubQXmAoIiIiIk6ZYxERERGRqGszx+s3\n7wBgaDbV+bYagwAU4oEdT0ymjGst1vC2E6ulXG1usZ3xzWp7U0YXvHZ4247p2Ce1VOOR0uUQ631D\nOvFj9OQVAIz0pSz0p679HAC/uv0XAPSdsC5rGzj1xQAMDse55LK+rTjpgvmcK5VKaov9Go14yIkV\n9moTEREREafMsYiIiIhIpOBYRERERCTq2rKK6295FIAptmb3BqpebtDb6wvWtm59KmurxQqD6Rkv\nrxiqpnKHwT7vH2L5Qr2RTpmbmfJyirGxCQCa1VTGMTDii+d6dvvCvLA7LdZrPLIBgBvu+EF275cP\nPQjAU0/4grwV9VQeMXy8n5oXKzto5k7bo5HKNQB6yml7uGL8/NOKCw6tqLIKOXzMbBR4BPjfIYRL\nlnQyIiIiB0GZYxERERGRqGszx9Mz/tJ2NlN2tNHyDO6uuAvarvGprK1e9K3YJqa8fyW35VkhZluL\n8aCQVjNllWcaPma95Rnn3mZakddXigvlWjsB2PTgHVnbigd/6X2GUv/pcV9E2Bez1sc3U6a5Z9Od\nAPSfsNZfS6Uva5tseebYip7RLpTT/AoVzzC3Jr2tkvs8FHIZcBERERHp4uBYRGSp3b15F6NXfHvB\nxtv40YsXbCwREelMZRUicliY2aiZfdXMtpnZjJn9i5n9mw79qmZ2hZn9ysymzGy3mf3MzP5gnjGD\nmX3RzE4zs6+Z2RYza5nZhbHPs8zs82b2kJlNm9mOOPbnzGxFhzHfZGY3mNlYnOd6M/sLM6vO7Ssi\nIt2vazPH7QVoIbforFH3MoJgXsrQyJUVtPB+pYYvsOurp3KHQsPLL3Zs9YVyWzY9nLVN7/QFf62J\nWAKRO1lv+0/6vc+0L9abfPrxrG151UsumoXcaXY1f+yy+JllTW6v5YGGj7/tX74FwM6p9Dy1sv8z\njhde6GOuGs7ayj2+qK9l/vgmuX2fc69RZIGdDNwCPAx8CVgOvBH4ppm9IoRwA4CZVYDvAxcA9wGf\nBfqANwBfM7PnhxDe32H8U4FfAA8Afwv0ArvNbC1wKzAIfAf4On5g5inAHwPXAtvbg5jZdcBbgE2x\n7xjwIuBq4OVm9sqw58bmIiLS5bo2OBaRJXUhcGUI4ar2DTP7O+B7wH8Cboi334sHxt8FXtMORM3s\nKjy4fp+ZXR9CuHnO+C8BPjI3cDazd+KB+LtDCJ+a09YPtHJ/vgQPjL8BvDmEMJ1ruxL4IHAZsMc4\nc5nZbfM0nbGvx4mIyJGpa4PjVog/A0PKjtbrvmiufafZSpnZAr6Irb5zCwAb7/xF1jbYmARgcpe3\nlSZ2ZG3HV33btL7KAABbx7KkFNNP+s/a9sl1x5XTIr8Qn2/Xtp3ZvXLT+1mvZ5zX/asLs7ZnveAs\nAP7xn34IwNh992Zty+OJeBse863gJh9Ime1qPGWvv+wLDmshbQ9Xq2tBnhw2jwL/NX8jhPB9M3sM\nOC93+634/5LvyWdoQwhbzOxq4K+BtwFzg+OngauY3/TcGyGEyTm3LgcawFvzgXF0NfAO4M08Q3As\nIiLdpWuDYxFZUneGEDp9+noc+A0AM1sGPBvYHEK4r0PfH8frCzq03RVCmO1w/x+ADwOfNbNX4SUb\nNwH3hpA+KZtZH3A2sA14t+V2p8mZBdZ1asgLIZzb6X7MKJ/zTI8XEZEjS/cGxx3KaZst/1ndLgtu\nNnOZ4+A/HG16HID65vuztjUrvS64XvbMc2tZqhMeHPAsb1+vZ45PXrMya7v7fj/owwrxUI647RvA\nlhlPYi1rpRrgnuDj75zdBcCZL/2NrO2cC18KwONbNvpQDz2QHlf0LPTgjNdGP3XTt9LrWulbxg1d\n8EZ/XM9A1jYbVHMsh83YPPcbpIXAQ/H65Dx92/eHO7Q91eEeIYRHzew84Erg1cDvxqbHzewTIYRP\nxz+PAAaswssnREREAO1WISJLZ1e8rpmnfe2cfnnzfrILIawPIbwRWAG8ELgCf6/7lJn9+zlj3hFC\nsH39d0CvSEREjnoKjkVkSYQQxoENwAlm9pwOXS6K19sPcvxGCOG2EMJ/A94Ub78utk0A9wDPNbPl\nBzO+iIh0p64tq2jFLdzyRY+N9ul1tQ6L9dizPHJwWSo/GDluFQCPPOLbts3mPlPMELdKe3IbAH0h\nbR3X014YHw+sW9bXn8Yf8XKKifFUNmm7vd5joOxlGL+6+QdZ2+5NXubx5K23AlDKlWgU+v23zpWi\nP99zRoaytse3+m+3Zzb5Yr3CqWmb11ZL27jKkrsO+BDwcTP7vXadspmtBP4y12e/mNm5wEMhhLnZ\n5uPidSp375PA3wDXmdklIYQ9SkHMbAQ4JYRwUME5wFknDHGbDu4QETmqdG1wLCJHhU8Avw28FrjL\nzL6D73P8+8Bq4GMhhBsPYLw/Bt5uZjfiWemd+J7Iv4MvsLum3TGEcF0Mpv8U2GBm3wcew7eCOwV4\nGfAF4NJDeoUiInJU6drguJ0UblrK8jZaXj5YbMbFd5Yyxy3zTGyh4PfKjdRWm/C2ygmnAbD81NOy\ntl213QCMPeiL7XdsuCdrq8TDP1Yv9yz0SF9fer6mL76rpUQztfEZAFZWfcFf6Ym06O6xB9f769nt\nO06VWynj3JjwOQwMjwBQ7UkZ6uWz/lq3jPnaJiO3wL9ZRmQphRBqZvZK4D3AHwLvxBft3YXvVfyV\nAxzyK0AVeDFwLn44yGbgq8B/DyHcPef5LzOz7+IB8CvwxX878CD548CXD/KliYjIUaprg2MRWXwh\nhI34LhDztV/Y4d4Mvv3ahxdg/F/gJ+fttxDC9cD1B/IYERHpXt0bHFs7O7z3z9FarAsu5ha8l2Mm\ntxi3Th2spnrcp8Y8Wzv7wlEAlp35/Kytd7dv/VZr9sVrylSXnvLMb3+vjzXbSqfQjhS8/8pGutdf\nDPHqmepVw2kHqzu2+s5Vk0X/JytXillbY9bnNzPpbZMT41nb9FTcfq7HNwQo5Oqsi8U0hoiIiIho\ntwoRERERkYyCYxERERGRqHvLKtrlA7mqimbTt2trtLytmitNIC7S277Ld3pqFNJfTd+JJwFQGvHd\noCrN3qytPy7y29AY9L4rTs3aymM7/HmmfcFcb1/aLq635GOM7U4lEEPxtL3dVV/A988z6WyE3Sef\nCUBPj8+98vRdWVvP7u0AjE/5gr6p2bTN20Qsqyit3PvMhEqlstc9ERERkWOZMsciIiIiIlHXZo6z\nxWa5BWjtg0HaJ89Wc5nTyVnv3xjwE2snm+k8gErFF8Ytm4mL4WZmsrbZup81UI4L//pWHZe1tcZX\n+1g7PXPcmkn7tj1S8K8fW50yzRMFn09l7ckAbFpxctbWKPjhHataniXuG3s4vdg+zw6b+RZwoZjb\n5q3m28m16vGAkdwivEJBn41ERERE8hQdiYiIiIhECo5FRERERKKuLasoFb1soTCbyioa9VhOYd5W\nLqUSgxAXsY2s9bKKU07/taztyY2PAvDE408D0CQtrFs27KUQ5T4/bW68nE7BO27EF9RN7njcr4VU\nxtHs9UV35dP/dXavYkMALO/z+Y3PpD2QLc612IilGWE6a5saPN7n/pzT/bXfd0PWtmP7FgBa8US9\n3DpDTNsci4iIiOxBmWMRERERkah7M8cxO1zJLzqLSddKfNX5zHEBz6yG4IvbGuV0Ol15lWdmmw1v\no6ectQ0u8wzw01s9yzvbTH+lrUnPVNcavkWbnbA6a+uZ3ApAtZ4W980sO9HnXvC5FFtpm7d6fO7Q\n42NNz6bsda3q2erWyc8FYHx9yhyX4kLBVnzxBUuZ9E6nB4qIiIgcy5Q5FhERERGJujZzXCx4hrRA\n2j7Ngmdbq2XP/PZWqllbqeBZ5EK8NlspMzsTYu1vTDk3iynjWhmItcNlz/L2tFKd8Ezd64Lr/av8\nOY5/ftY2ff9PfQ4TG7N7s/1eo1wv+JZsuV3XmIqHjdTwtvFdKQPc3+9tM/3+enpOe2H6e3jCt5qb\nmfFsdKuRXldZW7mJiIiI7EHRkYiIiIhIpOBYRI4qZrbRzDYu9TxERKQ7dW1ZRTmG/dVSYa977UV6\nlUKqWygTSyWKpfi4tOiu1K5viFcLqVSjr9cXw1VKvk1btb47a9s96aUW1RUnAdAaXpu1NQZPAGB2\nYkt2r3etlz7Ui70A5KZHf9nn1W/ep9m/PGvrWe0n6TWa/hqqa89Iz9Nzq19npwAIubKK3nIqKxER\nERERZY5FRA6buzfvYvSKbzN6xbeXeioiIrKfujdzXPS4v6+nJ7tXiVu3lWPGtNFIi9raadpyXHRX\nLqTMcX/JM7mVfs8Sh9mUHS7Fv8JKXORXqtXT40ZGfKw1vkVbs5ieb/DX/MCO7Y+le2Wrx6n4vWI5\nLfwb6vX5VXb4QSSV4aE09dWj/vjZmGoup7be1SsAqG/xQ06quUV4PeWu/ecXEREROSjKHIvIEcfc\nO8zsHjObMbPNZnatmQ3N079qZleY2a/MbMrMdpvZz8zsD/Yx/uVmdu/c8VXTLEo8CowAAAkbSURB\nVCJybOva1GFf3G6tbqk+eFnV7/WUPDPbakxlbQMxa1uNyddSI2WHV8TS3JF+b5xupjFb258EYLD2\nmD9+anvWFgZjtrfPn2d2JmWVKyUfo2a1dG/rPT5WWOlj12eztt6WZ6+feuxe79OfMuIrmpt8zuM+\nl2YrPU9rxDPaa4uD/hrC5qytbxciR6prgHcBTwKfB+rAa4HzgQqQ/Y9jZhXg+8AFwH3AZ4E+4A3A\n18zs+SGE988Z/7PAnwBPxPFrwGuA84ByfD4RETkGdW1wLCJHJzN7MR4YbwDOCyHsiPc/ANwArAUe\nzT3kvXhg/F3gNSH4xuRmdhVwC/A+M7s+hHBzvP9SPDB+ADg/hDAW778f+CFw/Jzxn2m+t83TdMY8\n90VE5AimsgoROdK8JV4/1A6MAUIIM8D7OvR/KxCA97QD49h/C3B1/OPbcv3/XW78sVz/2jzji4jI\nMaRrM8crd6z3a66sYmXcxmxwp2+xZrXs5yK1uv8Wtdnwa62ZTrqzWKJRfcqvgzOpHKP+gJc+rIpj\nT+8Yz9oaTb/XNzUYx06fRUrxc8ngZCrfCA0fa3jWF/LV62mxXiuO1Ts9A0B/MS0YrD78MACFuAix\nmDtab7AW59rnJ/n1j92RtS0rbkXkCHROvP60Q9uNQLYfoZktA54NbA4h3Neh/4/j9QW5e+2vb+zQ\n/+dAo8P9eYUQzu10P2aUz+nUJiIiRy5ljkXkSNNedPf03IaYGd7Woe+T84zVvj+8n+M3ge1z74uI\nyLGjazPHQ1vuBGBl7ufcroZnW2t1/0xQyy1ca8x6Mmp80rO3jUZaKNcbk7S1uLNaaKWDNNqfL5rm\nq/ZqtZmspRgPFAkzfq/aSllsM8/uFi19PqkVfau4qRCzvYWUoW7hWeTqkPe3QhortOLhJHE7Ost9\n5hke8pigEBcRDrdStri/tQyRI1B7qehxwMP5BjMrASuBTXP6rplnrLVz+gG0f13TafwisALYjIiI\nHJOUORaRI83t8XpBh7aXAFndUAhhHF+4d4KZPadD/4vmjAnQri16SYf+L2IBkwZnnTDExo9ezMaP\nXrxQQ4qIyGGm4FhEjjRfjNcPmFl2TrqZ9QAf6dD/OsCAj1v7VzLefyXwl7k+bf8nN/5Qrn8F+PAh\nz15ERI5qXVtWUV7mJQOlYjplrqe9wK3uPz/bi9wAqnVfgzPQ69dyrnSiN37dCv5ZokEas/1ly+Li\nu2Vp/2EzbyyH9nXvcow+0sK6hpViSzwhj7QgrxBPtgvxVrGYyirKJR+3GMsqisXcwr+yl2rUY9mH\nFSZS2/BaRI40IYSbzOwzwDuBu83s70n7HO9k7/riTwC/HdvvMrPv4Psc/z6wGvhYCOHG3Pg/NbPP\nA/8RuMfMvh7H/x28/OIJoIWIiByTujY4FpGj2uX4PsSXAW/HF8l9A3g/cFe+YwihZmavBN4D/CEe\nVDdiv3eHEL7SYfw/wQ8MeTtw6ZzxN+GlGodqdP369Zx7bsfNLEREZB/Wr18PMLoUz20hhGfuJSJy\nDIh1yw8AXw0hvOkQx5rF66Pveqa+IkukfVBNp20QRZba2UAzhFBd7CdW5lhEjjlmtgbYEkJo5e71\n4cdWg2eRD9XdMP8+yCJLrX26o75H5Ui0j9NHDzsFxyJyLHo38CYz+wlew7wGeDlwIn4M9f9duqmJ\niMhSUnAsIseif8R/ZfdbwHK8RvkB4NPANUH1ZiIixywFxyJyzAkh/Aj40VLPQ0REjjza51hERERE\nJFJwLCIiIiISaSs3EREREZFImWMRERERkUjBsYiIiIhIpOBYRERERCRScCwiIiIiEik4FhERERGJ\nFByLiIiIiEQKjkVEREREIgXHIiL7wcxONLPrzOwJM5s1s41mdo2ZjSzFOCJzLcT3VnxMmOe/pw7n\n/KW7mdkbzOwzZvYzM9sdv6e+fJBjHdb3UR0CIiLyDMzsVOBmYDXwTeA+4DzgIuB+4DdDCNsXaxyR\nuRbwe3QjMAxc06F5IoTwiYWasxxbzOxO4GxgAtgEnAH8bQjhjw5wnMP+Plo6lAeLiBwj/gf+Rvyu\nEMJn2jfN7JPAnwEfAi5dxHFE5lrI762xEMKVCz5DOdb9GR4UPwRcANxwkOMc9vdRZY5FRPYhZike\nAjYCp4YQWrm2ZcCTgAGrQwiTh3sckbkW8nsrZo4JIYwepumKYGYX4sHxAWWOF+t9VDXHIiL7dlG8\n/iD/RgwQQhgHbgL6gBct0jgicy3091bVzP7IzN5vZpeb2UVmVlzA+YocrEV5H1VwLCKyb6fH6wPz\ntD8Yr6ct0jgicy3099Ya4Ev4r6evAX4MPGhmFxz0DEUWxqK8jyo4FhHZt6F43TVPe/v+8CKNIzLX\nQn5vfQF4OR4g9wO/DvxPYBT4rpmdffDTFDlki/I+qgV5IiIiAkAI4ao5t+4GLjWzCeC9wJXA6xd7\nXiKLSZljEZF9a2cihuZpb98fW6RxROZajO+tz8Xryw5hDJFDtSjvowqORUT27f54na+G7TnxOl8N\n3EKPIzLXYnxvbY3X/kMYQ+RQLcr7qIJjEZF9a+/F+Vtmtsd7Ztw66DeBKeDnizSOyFyL8b3VXv3/\n8CGMIXKoFuV9VMGxiMg+hBA2AD/AFyRdNqf5KjyT9qX2nppmVjazM+J+nAc9jsj+WqjvUTNbZ2Z7\nZYbNbBS4Nv7xoI77FTkQS/0+qkNARESeQYfjStcD5+N7bj4AvLh9XGkMJB4BHp17kMKBjCNyIBbi\ne9TMrsQX3f0T8CgwDpwKXAz0AN8BXh9CqC3CS5IuY2avA14X/7gGeBX+m4ifxXvbQgh/HvuOsoTv\nowqORUT2g5mdBPwV8GpgBX4S0zeAq0IIO3P9RpnnTf1AxhE5UIf6PRr3Mb4UeAFpK7cx4E583+Mv\nBQUNcpDih68P7qNL9v241O+jCo5FRERERCLVHIuIiIiIRAqORUREREQiBcciIiIiIpGCYxERERGR\nSMGxiIiIiEik4FhEREREJFJwLCIiIiISKTgWEREREYkUHIuIiIiIRAqORUREREQiBcciIiIiIpGC\nYxERERGRSMGxiIiIiEik4FhEREREJFJwLCIiIiISKTgWEREREYkUHIuIiIiIRP8fFX4oa5QoM9MA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d809a16d8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
