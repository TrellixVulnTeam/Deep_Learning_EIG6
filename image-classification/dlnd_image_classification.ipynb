{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1af848dec88>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    im_max = 255\n",
    "    im_min = 0\n",
    "    return (x-im_min)/(im_max - im_min)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = np.array(x)\n",
    "    number_of_class = max(x)\n",
    "    enc_x = np.zeros((len(x),10))\n",
    "    print(enc_x[1,:])\n",
    "    for i in range(len(x)):\n",
    "        enc_x[i,x[i]] = 1.0\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    return enc_x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], 'x')\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], 'y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     s = x_tensor.get_shape()\n",
    "    \n",
    "#     shape = tuple([s[i].value for i in range(0, len(s))])\n",
    "#     x = [conv_ksize[0], conv_ksize[1], x_tensor[0][0][3], conv_num_outputs]\n",
    "    print(conv_ksize)\n",
    "    W_conv = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_tensor.get_shape()[3].value, conv_num_outputs], stddev=0.1))\n",
    "    b_conv = tf.Variable(tf.constant(0.1, shape=[conv_num_outputs]))\n",
    "    \n",
    "    conv = tf.nn.conv2d(x_tensor, W_conv, strides=[1,conv_strides[0],conv_strides[1],1], padding='SAME')\n",
    "    relu = tf.nn.relu(conv + b_conv)\n",
    "    output = tf.nn.max_pool(relu, ksize=[1,pool_ksize[0],pool_ksize[1],1],\n",
    "                        strides=[1,pool_strides[0],pool_strides[1],1], padding='SAME')\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    s = x_tensor.get_shape()\n",
    "    \n",
    "    shape = tuple([s[i].value for i in range(0, len(s))])\n",
    "    \n",
    "    return tf.reshape(x_tensor, [-1, shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    W_fc = tf.Variable(tf.truncated_normal([x_tensor.get_shape()[1].value, num_outputs], stddev=0.1))\n",
    "    b_fc = tf.Variable(tf.constant(0.1, shape=[num_outputs]))\n",
    "    relu = tf.nn.relu(tf.matmul(x_tensor, W_fc) + b_fc)\n",
    "    return relu\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    W_fc = tf.Variable(tf.truncated_normal([x_tensor.get_shape()[1].value, num_outputs], stddev=0.1))\n",
    "    b_fc = tf.Variable(tf.constant(0.1, shape=[num_outputs]))\n",
    "    out = tf.matmul(x_tensor, W_fc) + b_fc\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3]\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "[3, 3]\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv1 = conv2d_maxpool(x, 32, [3,3], [1,1], [2,2], [1, 1])\n",
    "    conv2 = conv2d_maxpool(conv1, 64, (3,3), (1,1), (1,1), (1, 1))\n",
    "    conv3 = conv2d_maxpool(conv2, 64, (3,3), (1,1), (2,2), (1, 1))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(conv1)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc = fully_conn(flat, 512)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = tf.nn.dropout(fc, keep_prob,name=\"keep_prob\")\n",
    "    final = output(out, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return final\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... current loss: <MagicMock name='mock()' id='1853383933680'>Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    import sys\n",
    "    train_feed_dict = {x: feature_batch, y: label_batch, keep_prob:keep_probability}\n",
    "    #l = session.run(cost, feed_dict=train_feed_dict)\n",
    "    l = session.run([cost,optimizer], feed_dict=train_feed_dict)\n",
    "    sys.stdout.write(\"\\r ... current loss: \" + str(l))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    import sys\n",
    "    train_feed_dict = {x: feature_batch, y: label_batch, keep_prob: 1.0}\n",
    "    l = session.run([cost], feed_dict=train_feed_dict)\n",
    "    valid_feed_dict = {x: valid_features, y: valid_labels, keep_prob: 1.0}\n",
    "    acc = session.run([accuracy], feed_dict=valid_feed_dict)\n",
    "    sys.stdout.write(\"\\r ...Validation loss: \" + str(l)[:5] \\\n",
    "                 + \" ... Validation accuracy: \" + str(acc)[:5] + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      " ... current loss: [5.4480143, None]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-10cd5fe04919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_preprocess_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {:>2}, CIFAR-10 Batch {}: \\n '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a2e292e64a75>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(session, optimizer, keep_probability, feature_batch, label_batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_feed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfeature_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mkeep_probability\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[1;31m#l = session.run(cost, feed_dict=train_feed_dict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_feed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r ... current loss: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\xinyu\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\xinyu\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\xinyu\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\xinyu\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\xinyu\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}: \\n '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      " ... current loss: [2.2853777, None]\n",
      "Epoch  1, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [2.13 ... Validation accuracy: [0.29\n",
      " ... current loss: [2.0461125, None]\n",
      "Epoch  1, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [1.88 ... Validation accuracy: [0.36\n",
      " ... current loss: [1.700922, None]]\n",
      "Epoch  1, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [1.66 ... Validation accuracy: [0.37\n",
      " ... current loss: [1.7790962, None]\n",
      "Epoch  1, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [1.68 ... Validation accuracy: [0.40\n",
      " ... current loss: [1.8329159, None]\n",
      "Epoch  1, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [1.69 ... Validation accuracy: [0.43\n",
      " ... current loss: [1.9620111, None]\n",
      "Epoch  2, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [1.73 ... Validation accuracy: [0.43\n",
      " ... current loss: [1.839172, None]]\n",
      "Epoch  2, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [1.58 ... Validation accuracy: [0.45\n",
      " ... current loss: [1.4929645, None]\n",
      "Epoch  2, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [1.42 ... Validation accuracy: [0.46\n",
      " ... current loss: [1.5857433, None]\n",
      "Epoch  2, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [1.46 ... Validation accuracy: [0.48\n",
      " ... current loss: [1.6936789, None]\n",
      "Epoch  2, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [1.46 ... Validation accuracy: [0.49\n",
      " ... current loss: [1.5973743, None]\n",
      "Epoch  3, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [1.45 ... Validation accuracy: [0.49\n",
      " ... current loss: [1.5949032, None]\n",
      "Epoch  3, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [1.37 ... Validation accuracy: [0.50\n",
      " ... current loss: [1.5640295, None]\n",
      "Epoch  3, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [1.23 ... Validation accuracy: [0.48\n",
      " ... current loss: [1.4874092, None]\n",
      "Epoch  3, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [1.34 ... Validation accuracy: [0.51\n",
      " ... current loss: [1.6342971, None]\n",
      "Epoch  3, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [1.35 ... Validation accuracy: [0.51\n",
      " ... current loss: [1.4861985, None]\n",
      "Epoch  4, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [1.44 ... Validation accuracy: [0.52\n",
      " ... current loss: [1.5372337, None]\n",
      "Epoch  4, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [1.25 ... Validation accuracy: [0.52\n",
      " ... current loss: [1.4685911, None]\n",
      "Epoch  4, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [1.13 ... Validation accuracy: [0.52\n",
      " ... current loss: [1.3133457, None]\n",
      "Epoch  4, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [1.21 ... Validation accuracy: [0.54\n",
      " ... current loss: [1.3083385, None]\n",
      "Epoch  4, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [1.22 ... Validation accuracy: [0.53\n",
      " ... current loss: [1.8085442, None]\n",
      "Epoch  5, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [1.30 ... Validation accuracy: [0.53\n",
      " ... current loss: [1.5702384, None]\n",
      "Epoch  5, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [1.14 ... Validation accuracy: [0.53\n",
      " ... current loss: [1.154597, None]]\n",
      "Epoch  5, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [1.02 ... Validation accuracy: [0.54\n",
      " ... current loss: [1.2910664, None]\n",
      "Epoch  5, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [1.19 ... Validation accuracy: [0.54\n",
      " ... current loss: [1.3022072, None]\n",
      "Epoch  5, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [1.15 ... Validation accuracy: [0.55\n",
      " ... current loss: [1.3173413, None]\n",
      "Epoch  6, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [1.16 ... Validation accuracy: [0.56\n",
      " ... current loss: [1.2775253, None]\n",
      "Epoch  6, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [1.05 ... Validation accuracy: [0.55\n",
      " ... current loss: [1.2078485, None]\n",
      "Epoch  6, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.92 ... Validation accuracy: [0.56\n",
      " ... current loss: [1.3578622, None]\n",
      "Epoch  6, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [1.09 ... Validation accuracy: [0.56\n",
      " ... current loss: [1.2325796, None]\n",
      "Epoch  6, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [1.03 ... Validation accuracy: [0.57\n",
      " ... current loss: [1.5513664, None]\n",
      "Epoch  7, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [1.07 ... Validation accuracy: [0.58\n",
      " ... current loss: [1.2941492, None]\n",
      "Epoch  7, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [1.02 ... Validation accuracy: [0.56\n",
      " ... current loss: [1.0981953, None]\n",
      "Epoch  7, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.87 ... Validation accuracy: [0.57\n",
      " ... current loss: [1.203449, None]]\n",
      "Epoch  7, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [1.00 ... Validation accuracy: [0.58\n",
      " ... current loss: [1.2008771, None]\n",
      "Epoch  7, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [1.05 ... Validation accuracy: [0.57\n",
      " ... current loss: [1.279994, None]]\n",
      "Epoch  8, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.99 ... Validation accuracy: [0.59\n",
      " ... current loss: [1.0744565, None]\n",
      "Epoch  8, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.86 ... Validation accuracy: [0.58\n",
      " ... current loss: [0.86002922, None]\n",
      "Epoch  8, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.85 ... Validation accuracy: [0.58\n",
      " ... current loss: [1.1486595, None]\n",
      "Epoch  8, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.87 ... Validation accuracy: [0.59\n",
      " ... current loss: [1.1503862, None]\n",
      "Epoch  8, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.92 ... Validation accuracy: [0.59\n",
      " ... current loss: [1.3258832, None]\n",
      "Epoch  9, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.96 ... Validation accuracy: [0.60\n",
      " ... current loss: [1.0183138, None]\n",
      "Epoch  9, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.80 ... Validation accuracy: [0.59\n",
      " ... current loss: [1.1139122, None]\n",
      "Epoch  9, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.77 ... Validation accuracy: [0.59\n",
      " ... current loss: [0.95989245, None]\n",
      "Epoch  9, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.81 ... Validation accuracy: [0.60\n",
      " ... current loss: [1.0771034, None]\n",
      "Epoch  9, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.82 ... Validation accuracy: [0.59\n",
      " ... current loss: [1.092894, None]]]\n",
      "Epoch 10, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.85 ... Validation accuracy: [0.60\n",
      " ... current loss: [0.9861145, None]\n",
      "Epoch 10, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.74 ... Validation accuracy: [0.59\n",
      " ... current loss: [0.94793022, None]\n",
      "Epoch 10, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.66 ... Validation accuracy: [0.60\n",
      " ... current loss: [0.90920198, None]\n",
      "Epoch 10, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.72 ... Validation accuracy: [0.61\n",
      " ... current loss: [1.0556253, None]]\n",
      "Epoch 10, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.75 ... Validation accuracy: [0.59\n",
      " ... current loss: [1.0362937, None]]\n",
      "Epoch 11, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.84 ... Validation accuracy: [0.60\n",
      " ... current loss: [1.0763285, None]]\n",
      "Epoch 11, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.69 ... Validation accuracy: [0.61\n",
      " ... current loss: [0.84206122, None]\n",
      "Epoch 11, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.66 ... Validation accuracy: [0.61\n",
      " ... current loss: [1.0024393, None]]\n",
      "Epoch 11, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.70 ... Validation accuracy: [0.62\n",
      " ... current loss: [1.0257564, None]]\n",
      "Epoch 11, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.70 ... Validation accuracy: [0.61\n",
      " ... current loss: [1.1029403, None]]\n",
      "Epoch 12, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.75 ... Validation accuracy: [0.61\n",
      " ... current loss: [0.79632282, None]\n",
      "Epoch 12, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.60 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.67066294, None]\n",
      "Epoch 12, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.52 ... Validation accuracy: [0.61\n",
      " ... current loss: [0.85631305, None]\n",
      "Epoch 12, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.63 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.76423854, None]\n",
      "Epoch 12, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.62 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.94889802, None]\n",
      "Epoch 13, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.70 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.81515443, None]\n",
      "Epoch 13, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.53 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.70352161, None]\n",
      "Epoch 13, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.48 ... Validation accuracy: [0.61\n",
      " ... current loss: [0.99755228, None]\n",
      "Epoch 13, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.61 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.88634032, None]\n",
      "Epoch 13, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.56 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.97605479, None]\n",
      "Epoch 14, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.63 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.71857452, None]\n",
      "Epoch 14, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.47 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.52904111, None]\n",
      "Epoch 14, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.41 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.76342058, None]\n",
      "Epoch 14, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.59 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.76159585, None]\n",
      "Epoch 14, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.49 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.76263428, None]\n",
      "Epoch 15, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.58 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.73230433, None]\n",
      "Epoch 15, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.47 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.68010747, None]\n",
      "Epoch 15, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.38 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.73698485, None]\n",
      "Epoch 15, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.54 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.66509235, None]\n",
      "Epoch 15, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.41 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.84797651, None]\n",
      "Epoch 16, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.52 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.8095479, None]]\n",
      "Epoch 16, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.45 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.75316417, None]\n",
      "Epoch 16, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.34 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.75786889, None]\n",
      "Epoch 16, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.44 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.59541285, None]\n",
      "Epoch 16, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.39 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.78278011, None]\n",
      "Epoch 17, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.45 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.60087502, None]\n",
      "Epoch 17, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.39 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.53542364, None]\n",
      "Epoch 17, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.37 ... Validation accuracy: [0.62\n",
      " ... current loss: [0.69920444, None]\n",
      "Epoch 17, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.42 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.53469431, None]\n",
      "Epoch 17, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.37 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.71325809, None]\n",
      "Epoch 18, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.41 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.64881754, None]\n",
      "Epoch 18, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.35 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.61320364, None]\n",
      "Epoch 18, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.31 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.51706755, None]\n",
      "Epoch 18, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.37 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.65670598, None]\n",
      "Epoch 18, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.30 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.59452897, None]\n",
      "Epoch 19, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.34 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.52791137, None]\n",
      "Epoch 19, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.37 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.47211272, None]\n",
      "Epoch 19, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.25 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.56244123, None]\n",
      "Epoch 19, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.34 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.48855704, None]\n",
      "Epoch 19, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.30 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.75322092, None]\n",
      "Epoch 20, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.34 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.34749824, None]\n",
      "Epoch 20, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.25 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.42129111, None]\n",
      "Epoch 20, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.24 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.53429234, None]\n",
      "Epoch 20, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.30 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.42304546, None]\n",
      "Epoch 20, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.25 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.56223643, None]\n",
      "Epoch 21, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.31 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.49215785, None]\n",
      "Epoch 21, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.23 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.41692224, None]\n",
      "Epoch 21, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.22 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.43685818, None]\n",
      "Epoch 21, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.28 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.45602745, None]\n",
      "Epoch 21, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.21 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.39088696, None]\n",
      "Epoch 22, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.27 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.39957654, None]\n",
      "Epoch 22, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.24 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.34498653, None]\n",
      "Epoch 22, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.16 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.57577246, None]\n",
      "Epoch 22, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.23 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.50500768, None]\n",
      "Epoch 22, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.21 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.41418833, None]\n",
      "Epoch 23, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.24 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.46332502, None]\n",
      "Epoch 23, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.25 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.54520786, None]\n",
      "Epoch 23, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.14 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.28526276, None]\n",
      "Epoch 23, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.18 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.51472771, None]\n",
      "Epoch 23, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.18 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.62711793, None]\n",
      "Epoch 24, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.21 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.54883444, None]\n",
      "Epoch 24, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.21 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.32363942, None]\n",
      "Epoch 24, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.10 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.54806304, None]\n",
      "Epoch 24, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.16 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.32581413, None]\n",
      "Epoch 24, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.15 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.31461677, None]\n",
      "Epoch 25, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.16 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.30608016, None]\n",
      "Epoch 25, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.14 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.27204216, None]\n",
      "Epoch 25, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.09 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.22140877, None]\n",
      "Epoch 25, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.12 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.37730345, None]\n",
      "Epoch 25, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.13 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.42822188, None]\n",
      "Epoch 26, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.13 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.44142213, None]\n",
      "Epoch 26, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.12 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.39750111, None]\n",
      "Epoch 26, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.11 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.35500312, None]\n",
      "Epoch 26, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.09 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.26363739, None]\n",
      "Epoch 26, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.12 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.3632901, None]]\n",
      "Epoch 27, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.12 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.33626533, None]\n",
      "Epoch 27, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.09 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.42998847, None]\n",
      "Epoch 27, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.08 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.2515499, None]]\n",
      "Epoch 27, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.08 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.36727643, None]\n",
      "Epoch 27, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.10 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.3523128, None]]\n",
      "Epoch 28, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.11 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.22295812, None]\n",
      "Epoch 28, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.07 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.27479166, None]\n",
      "Epoch 28, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.08 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.21668272, None]\n",
      "Epoch 28, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.08 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.40832844, None]\n",
      "Epoch 28, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.09 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.32798347, None]\n",
      "Epoch 29, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.09 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.34880263, None]\n",
      "Epoch 29, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.07 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.20621681, None]\n",
      "Epoch 29, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.05 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.24870698, None]\n",
      "Epoch 29, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.07 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.26607788, None]\n",
      "Epoch 29, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.09 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.45228124, None]\n",
      "Epoch 30, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.10 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.16196418, None]\n",
      "Epoch 30, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.05 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.19680636, None]\n",
      "Epoch 30, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.06 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.24402547, None]\n",
      "Epoch 30, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.07 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.1845672, None]]\n",
      "Epoch 30, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.08 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.19795118, None]\n",
      "Epoch 31, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.07 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.19477606, None]\n",
      "Epoch 31, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.05 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.30051923, None]\n",
      "Epoch 31, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.04 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.25144643, None]\n",
      "Epoch 31, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.04 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.30543533, None]\n",
      "Epoch 31, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.08 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.34389311, None]\n",
      "Epoch 32, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.09 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.15539737, None]\n",
      "Epoch 32, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.11011853, None]\n",
      "Epoch 32, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.17226574, None]\n",
      "Epoch 32, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.04 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.19877055, None]\n",
      "Epoch 32, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.06 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.36593664, None]\n",
      "Epoch 33, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.07 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.16223419, None]\n",
      "Epoch 33, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.17878829, None]\n",
      "Epoch 33, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.21506412, None]\n",
      "Epoch 33, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.04 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.20499596, None]\n",
      "Epoch 33, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.05 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.23673701, None]\n",
      "Epoch 34, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.20821278, None]\n",
      "Epoch 34, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.14815359, None]\n",
      "Epoch 34, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.29607639, None]\n",
      "Epoch 34, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.16997305, None]\n",
      "Epoch 34, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.05 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.20181444, None]\n",
      "Epoch 35, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.05 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.17776808, None]\n",
      "Epoch 35, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.22488639, None]\n",
      "Epoch 35, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.13711207, None]\n",
      "Epoch 35, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.16762583, None]\n",
      "Epoch 35, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.04 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.24715149, None]\n",
      "Epoch 36, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.05 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.15599439, None]\n",
      "Epoch 36, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.22546232, None]\n",
      "Epoch 36, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.23121767, None]\n",
      "Epoch 36, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.37304449, None]\n",
      "Epoch 36, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.04 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.19145669, None]\n",
      "Epoch 37, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.06 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.26709455, None]\n",
      "Epoch 37, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.15229981, None]\n",
      "Epoch 37, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.11592703, None]\n",
      "Epoch 37, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.1575482, None]]\n",
      "Epoch 37, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.04 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.31792831, None]\n",
      "Epoch 38, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.14040403, None]\n",
      "Epoch 38, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.17888469, None]\n",
      "Epoch 38, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.19443533, None]\n",
      "Epoch 38, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.3472181, None]]\n",
      "Epoch 38, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.05 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.13584301, None]\n",
      "Epoch 39, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.19066942, None]\n",
      "Epoch 39, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.060812108, None]\n",
      "Epoch 39, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.14464228, None]\n",
      "Epoch 39, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.1873666, None]]\n",
      "Epoch 39, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.2442607, None]]\n",
      "Epoch 40, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.20155375, None]\n",
      "Epoch 40, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.1237448, None]]\n",
      "Epoch 40, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.086484946, None]\n",
      "Epoch 40, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.28432265, None]\n",
      "Epoch 40, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.15182774, None]\n",
      "Epoch 41, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.082566217, None]\n",
      "Epoch 41, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.14607206, None]\n",
      "Epoch 41, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.0599957, None]]\n",
      "Epoch 41, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.1801658, None]]\n",
      "Epoch 41, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.096167803, None]\n",
      "Epoch 42, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.22238326, None]\n",
      "Epoch 42, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.17756382, None]\n",
      "Epoch 42, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.16752924, None]\n",
      "Epoch 42, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.2211431, None]]\n",
      "Epoch 42, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.04 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.25794914, None]\n",
      "Epoch 43, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.63\n",
      " ... current loss: [0.25096226, None]\n",
      "Epoch 43, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.12691572, None]\n",
      "Epoch 43, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.081678398, None]\n",
      "Epoch 43, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.13468111, None]\n",
      "Epoch 43, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.25905091, None]\n",
      "Epoch 44, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.18369761, None]\n",
      "Epoch 44, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.17858092, None]\n",
      "Epoch 44, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.11905302, None]\n",
      "Epoch 44, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.12470714, None]\n",
      "Epoch 44, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.19841829, None]\n",
      "Epoch 45, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.070340015, None]\n",
      "Epoch 45, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.096475713, None]\n",
      "Epoch 45, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.19800483, None]\n",
      "Epoch 45, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.28784567, None]\n",
      "Epoch 45, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.26571897, None]\n",
      "Epoch 46, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.10103085, None]\n",
      "Epoch 46, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.20161481, None]\n",
      "Epoch 46, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.2508536, None]]\n",
      "Epoch 46, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.164213, None]e]\n",
      "Epoch 46, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.15250395, None]\n",
      "Epoch 47, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.098032191, None]\n",
      "Epoch 47, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.081642486, None]\n",
      "Epoch 47, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.14714491, None]\n",
      "Epoch 47, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.01 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.13418606, None]\n",
      "Epoch 47, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.066592738, None]\n",
      "Epoch 48, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.19423011, None]\n",
      "Epoch 48, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.22445969, None]\n",
      "Epoch 48, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.015643984, None]\n",
      "Epoch 48, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.22792511, None]\n",
      "Epoch 48, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.18306249, None]\n",
      "Epoch 49, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.35008875, None]\n",
      "Epoch 49, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.13012245, None]\n",
      "Epoch 49, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.10574792, None]\n",
      "Epoch 49, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.64\n",
      " ... current loss: [0.13764073, None]\n",
      "Epoch 49, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.03 ... Validation accuracy: [0.65\n",
      " ... current loss: [0.24334519, None]\n",
      "Epoch 50, CIFAR-10 Batch 1: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.22409943, None]\n",
      "Epoch 50, CIFAR-10 Batch 2: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.097717002, None]\n",
      "Epoch 50, CIFAR-10 Batch 3: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.14661309, None]\n",
      "Epoch 50, CIFAR-10 Batch 4: \n",
      " ...Validation loss: [0.00 ... Validation accuracy: [0.66\n",
      " ... current loss: [0.076747566, None]\n",
      "Epoch 50, CIFAR-10 Batch 5: \n",
      " ...Validation loss: [0.02 ... Validation accuracy: [0.65\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('\\nEpoch {:>2}, CIFAR-10 Batch {}: \\n '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6541732594936709\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1affce75550>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
